<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<!--<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>-->
<!--<script type="text/x-mathjax-config">MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "AMS"} } });</script>-->
<head>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script type="text/x-mathjax-config">MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "AMS"} } });</script>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
<script>
  function resizeIframe(obj) {
    obj.style.height = obj.contentWindow.document.body.scrollHeight + 'px';
  }
</script>

<meta charset="utf-8">
<title>Derivation of a Weighted Recursive Linear Least Squares Estimator &#8211; ML & Stats</title>
<meta name="description" content="Describe your website here.">
<meta name="keywords" content="">



<!-- Open Graph -->
<meta property="og:locale" content="en">
<meta property="og:type" content="article">
<meta property="og:title" content="Derivation of a Weighted Recursive Linear Least Squares Estimator">
<meta property="og:description" content="Describe your website here.">
<meta property="og:url" content="https://MarkusThill.github.io/derivation-of-a-weighted-recursive-least-squares-estimator/">
<meta property="og:site_name" content="ML & Stats">
<meta property="og:image" content="https://MarkusThill.github.io/images/images/logo.png">





<link rel="canonical" href="https://MarkusThill.github.io/derivation-of-a-weighted-recursive-least-squares-estimator/">
<link href="https://MarkusThill.github.io/feed.xml" type="application/atom+xml" rel="alternate" title="ML & Stats Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no"/>

<!-- For all browsers -->
<link rel="stylesheet" href="https://MarkusThill.github.io/assets/css/main.css">
<link rel="stylesheet" href="https://MarkusThill.github.io/assets/css/jquery.mmenu.all.css">
<link rel="stylesheet" href="https://MarkusThill.github.io/assets/css/jquery.floating-social-share.min.css">
<!-- Webfonts -->
<link href="//fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic" rel="stylesheet" type="text/css">

<meta http-equiv="cleartype" content="on">

<!-- Load Modernizr -->
<script type="text/javascript" src="https://MarkusThill.github.io/assets/js/vendor/modernizr-2.6.2.custom.min.js"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="https://MarkusThill.github.io/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="https://MarkusThill.github.io/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="https://MarkusThill.github.io/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="https://MarkusThill.github.io/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="https://MarkusThill.github.io/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://MarkusThill.github.io/images/apple-touch-icon-144x144-precomposed.png">




<!--<link rel="stylesheet" type="text/css" href="https://cdn.rawgit.com/dreampulse/computer-modern-web-font/master/fonts.css">-->
<link rel="stylesheet" href="/fonts/cmun-serif.css"></link>

<!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Derivation of a Weighted Recursive Linear Least Squares Estimator | ML &amp; Stats</title>
<meta name="generator" content="Jekyll v3.8.6" />
<meta property="og:title" content="Derivation of a Weighted Recursive Linear Least Squares Estimator" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="\( \let\vec\mathbf \def\myT{\mathsf{T}} \def\mydelta{\boldsymbol{\delta}} \def\matr#1{\mathbf #1} \) In this post we derive an incremental version of the weighted least squares estimator, described in a previous blog post." />
<meta property="og:description" content="\( \let\vec\mathbf \def\myT{\mathsf{T}} \def\mydelta{\boldsymbol{\delta}} \def\matr#1{\mathbf #1} \) In this post we derive an incremental version of the weighted least squares estimator, described in a previous blog post." />
<link rel="canonical" href="https://markusthill.github.io/derivation-of-a-weighted-recursive-least-squares-estimator/" />
<meta property="og:url" content="https://markusthill.github.io/derivation-of-a-weighted-recursive-least-squares-estimator/" />
<meta property="og:site_name" content="ML &amp; Stats" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-05-05T22:12:28+02:00" />
<script type="application/ld+json">
{"description":"\\( \\let\\vec\\mathbf \\def\\myT{\\mathsf{T}} \\def\\mydelta{\\boldsymbol{\\delta}} \\def\\matr#1{\\mathbf #1} \\) In this post we derive an incremental version of the weighted least squares estimator, described in a previous blog post.","headline":"Derivation of a Weighted Recursive Linear Least Squares Estimator","dateModified":"2019-05-05T22:12:28+02:00","datePublished":"2019-05-05T22:12:28+02:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://markusthill.github.io/derivation-of-a-weighted-recursive-least-squares-estimator/"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://markusthill.github.io/images/logo.png"}},"url":"https://markusthill.github.io/derivation-of-a-weighted-recursive-least-squares-estimator/","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

</head>

<body id="post" >

<!--[if lt IE 9]><div class="upgrade"><strong><a href="https://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->



<div class="header-menu header-menu-top">
    <ul class="header-item-container">
      <li class="header-item-title header-toggle "><a href="#menu"><h2><i class="fa fa-bars"></i></h2></a></li>
      <li class="header-item-title">
        <a href="https://MarkusThill.github.io/">
          
            <img class="logo" src="https://MarkusThill.github.io/images/logo.png" alt="ML & Stats">
          
          <a href="https://MarkusThill.github.io/" class="title"> ML & Stats</a>
        </a>
      </li>
      
        
        

        
            
                <li class="header-item "><a href="https://MarkusThill.github.io/posts"><h3>Posts</h3></a></li>
            
        
      
        
        

        
          <li class="header-item "><a href="https://MarkusThill.github.io/categories"><h3>Categories</h3></a>
            <ul class="header-submenu">
              
                
                  <li class="sub-item"><a href="https://MarkusThill.github.io/categories/#Electronics">Electronics</a></li>
              
                
                  <li class="sub-item"><a href="https://MarkusThill.github.io/categories/#ML">ML</a></li>
              
                
                  <li class="sub-item"><a href="https://MarkusThill.github.io/categories/#Math">Math</a></li>
              
                
                  <li class="sub-item"><a href="https://MarkusThill.github.io/categories/#Programming">Programming</a></li>
              
                
                  <li class="sub-item"><a href="https://MarkusThill.github.io/categories/#Stats">Stats</a></li>
              
                
                  <li class="sub-item"><a href="https://MarkusThill.github.io/categories/#Template">Template</a></li>
              
                
                  <li class="sub-item"><a href="https://MarkusThill.github.io/categories/#Vector Algebra">Vector Algebra</a></li>
              
            </ul>
          </li>
        
      
        
        

        
            
                <li class="header-item "><a href="https://MarkusThill.github.io/tags"><h3>Tags</h3></a></li>
            
        
      
        
        

        
            
                <li class="header-item "><a href="https://MarkusThill.github.io/markus"><h3>About</h3></a></li>
            
        
      
        
        

        
            
                <li class="header-item "><a href="https://MarkusThill.github.io/"><h3>Home</h3></a></li>
            
        
      
      <li class="header-item"><a href="https://MarkusThill.github.io/search"><h3><i class="fa fa-search"></i></h3></a></li>
    </ul>
  </div>
<div class="entry-header">
  <div class="header-title">
    <div class="header-title-wrap">
      <h1>Derivation of a Weighted Recursive Linear Least Squares Estimator</h1>
      
        <h2><span class="entry-date date published updated"><time datetime="2019-05-05T22:12:28+02:00">May 05, 2019</time></span></h2>
      

      
        <p class="entry-reading-time">
          <i class="fa fa-clock-o"></i>
          
          Reading time ~2 minutes
        </p><!-- /.entry-reading-time -->
      
    </div><!-- /.header-title-wrap -->
  </div><!-- /.header-title -->
</div><!-- /.entry-header -->


<nav id="menu" style="display: none">
  <ul>
    
      
        <li><a href="https://MarkusThill.github.io/"><h3>Home</h3></a></li>
      
    
      
        <li><a href="https://MarkusThill.github.io/markus"><h3>About</h3></a></li>
      
    
      
        <li><a href="https://MarkusThill.github.io/tags"><h3>Tags</h3></a></li>
      
    
      
        <li><a href="https://MarkusThill.github.io/categories"><h3>Categories</h3></a>
          <ul>
            
              
                <li><a href="https://MarkusThill.github.io/categories/#Electronics">Electronics</a></li>
            
              
                <li><a href="https://MarkusThill.github.io/categories/#ML">ML</a></li>
            
              
                <li><a href="https://MarkusThill.github.io/categories/#Math">Math</a></li>
            
              
                <li><a href="https://MarkusThill.github.io/categories/#Programming">Programming</a></li>
            
              
                <li><a href="https://MarkusThill.github.io/categories/#Stats">Stats</a></li>
            
              
                <li><a href="https://MarkusThill.github.io/categories/#Template">Template</a></li>
            
              
                <li><a href="https://MarkusThill.github.io/categories/#Vector Algebra">Vector Algebra</a></li>
            
          </ul>
        </li>
      
    
      
        <li><a href="https://MarkusThill.github.io/posts"><h3>Posts</h3></a></li>
      
    
  </ul>
</nav>




<div id="main" role="main">
  <article class="hentry">
    <div class="entry-content">
        
      <h1 class="post-title entry-title">Derivation of a Weighted Recursive Linear Least Squares Estimator</h1>
      <p>\( <br />
  \let\vec\mathbf
  \def\myT{\mathsf{T}}
  \def\mydelta{\boldsymbol{\delta}}
  \def\matr#1{\mathbf #1}
\)</p>

<p>In this post we derive an incremental version of the weighted least squares estimator, described in a previous <strong><a href="/math/stats/ml/the-weighted-least-squares-algorithm/">blog post</a></strong>.</p>

<!--more-->
<p>We start with the original closed form formulation of the weighted least squares estimator:</p>

<p>\begin{align}
  \boldsymbol{\theta} = \big(\matr X^\myT \matr W \matr X + \lambda \matr I\big)^{-1} \matr X^\myT \matr W \vec y.
\end{align}</p>

<p>where <script type="math/tex">\matr X</script> is a matrix containing <script type="math/tex">n</script> inputs of length <script type="math/tex">k</script> as row-vectors, <script type="math/tex">\matr W</script> is a diagonal weight matrix, containing a weight for each of the <script type="math/tex">n</script> observations, <script type="math/tex">\vec y</script> is the <script type="math/tex">n</script>-dimensional  output vector containing one value for each input vector (we can easily extend or explications to multi-dimensional outputs, where we would instead use a matrix <script type="math/tex">\matr Y</script>). The term <script type="math/tex">\lambda \matr I</script> (regularization factor and identity matrix) is the so called regularizer, which is used to prevent overfitting.</p>

<p>Since we have <script type="math/tex">n</script> observations we can also slightly modify our above equation, to later indicate the current iteration:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
  \boldsymbol{\theta}_n &= \big(\overbrace{\underbrace{ \matr X_n^\myT \matr W_n }_{=\matr G_n} \matr X_n + \lambda \matr I }^{=\matr A_n}\big)^{-1}\overbrace{ \underbrace{\matr X_n^\myT \matr W_n}_{=\matr G_n} \vec y_n }^{=\vec b_n} \label{eq:weightedRLS} \\
  &= \big(\overbrace{\matr G_n \matr X_n + \lambda \matr I }^{=\matr A_n}\big)^{-1}\overbrace{ \matr G_n \vec y_n }^{=\vec b_n} \\
  &= \matr A_n^{-1} \vec b_n
\end{align} %]]></script>

<p>The dimensions are as follows:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
  & \boldsymbol{\theta}_n \in \mathbb{R}^{k},
  \ \matr X_n \in \mathbb{R}^{n \times k},
  \ \matr W_n \in \mathbb{R}^{n \times n},
  \  \matr I \in \mathbb{R}^{k \times k},
  \  \matr \lambda \in \mathbb{R},
  \ \vec y_n \in \mathbb{R}^{n} \\
& \matr G_n \in \mathbb{R}^{k \times n}, \ \matr A_n \in \mathbb{R}^{k \times k}, \ \vec b_n \in \mathbb{R}^{k}
\end{align} %]]></script>

<p>If now a new observation pair <script type="math/tex">\vec x_{n+1} \in \mathbb{R}^{k} \ , y \in \mathbb{R}</script> arrives, some of the above matrices and vectors change as follows (the others remain unchanged):</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
  \ \matr X_{n+1} = \begin{bmatrix} \matr X_n \\ \vec x_{n+1}^\myT \end{bmatrix},
  \ \matr W_{n+1} = \begin{bmatrix} \matr W_n & \vec 0 \\ \vec 0^\myT & w_{n+1} \end{bmatrix},
  \ \vec y_{n+1} = \begin{bmatrix} \vec y_{n} \\ y_{n+1} \end{bmatrix}, \label{eq:newpoint}
\end{align} %]]></script>

<p>where</p>

<p>\begin{align}
  \ \matr X_{n+1} \in \mathbb{R}^{(n+1) \times k},
  \ \vec x_{n+1} \in \mathbb{k},
  \ \matr W_{n+1} \in \mathbb{R}^{(n+1) \times (n+1)},
  \ w_{n+1} \in \mathbb{R},
  \ \vec y_{n+1} \in \mathbb{R}^{n+1},
  \ y_{n+1} \in \mathbb{R}.
\end{align}</p>

<p>Now let us insert Eq. \eqref{eq:newpoint} into Eq. \eqref{eq:weightedRLS} and see what changes:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
  \boldsymbol{\theta}_{n+1} &= \Bigg(
    \overbrace{
    \underbrace{
    \begin{bmatrix} \matr X_n \\ \vec x_{n+1}^\myT \end{bmatrix}^\myT
    \begin{bmatrix} \matr W_n & \vec 0 \\ \vec 0^\myT & w_{n+1} \end{bmatrix}
    }_{=\matr G_{n+1}}
    \begin{bmatrix} \matr X_n \\ \vec x_{n+1}^\myT \end{bmatrix}
    + \lambda \matr I
    }^{=\matr A_{n+1}}
    \Bigg)^{-1}
    \overbrace{
    \underbrace{
    \begin{bmatrix} \matr X_n \\ \vec x_{n+1}^\myT \end{bmatrix}^\myT
    \begin{bmatrix} \matr W_n & \vec 0 \\ \vec 0^\myT & w_{n+1} \end{bmatrix}
    }_{=\matr G_{n+1}}
    \begin{bmatrix} \vec y_{n} \\ y_{n+1} \end{bmatrix}
    }^{=\vec b_{n+1}} \\
    &=
    \Bigg(
    \overbrace{
    \matr G_{n+1}
    \begin{bmatrix} \matr X_n \\ \vec x_{n+1}^\myT \end{bmatrix}
    + \lambda \matr I
    }^{=\matr A_{n+1}}
    \Bigg)^{-1}
    \overbrace{
    \matr G_{n+1}
    \begin{bmatrix} \vec y_{n} \\ y_{n+1} \end{bmatrix}
    }^{=\vec b_{n+1}} \\
    &=
    \big(
    \matr A_{n+1}
    \big)^{-1}
    \vec b_{n+1}, \label{eq:phi}
\end{align} %]]></script>

<p>where we identified:</p>

<p><script type="math/tex">% <![CDATA[
\begin{align}
\matr G_{n+1} &= \begin{bmatrix} \matr X_n \\ \vec x_{n+1}^\myT \end{bmatrix}^\myT \begin{bmatrix} \matr W_n & \vec 0 \\ \vec 0^\myT & w_{n+1} \end{bmatrix} \label{eq:Gnp1}
,\\
\matr A_{n+1} &= \matr G_{n+1} \begin{bmatrix} \matr X_n \\ \vec x_{n+1}^\myT \end{bmatrix} + \lambda \matr I \label{eq:Ap1}
,\\
\vec b_{n+1} &= \matr G_{n+1} \begin{bmatrix} \vec y_{n} \\ y_{n+1} \end{bmatrix}, \label{eq:Bp1}
\end{align} %]]></script>
with the dimensions</p>

<p>\begin{align}
\matr G_{n+1} \in \mathbb{R}^{k \times (n+1)}, \ \matr A_{n+1} \in \mathbb{R}^{k \times k}, \ \vec b_{n+1} \in \mathbb{R}^{k}.
\end{align}</p>

<p>Now let us expand equation \eqref{eq:Gnp1}:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\matr G_{n+1} &= \begin{bmatrix} \overbrace{\matr X_n}^{n \times k} \\ \underbrace{\vec x_{n+1}^\myT}_{1 \times k} \end{bmatrix}^\myT
\begin{bmatrix} \overbrace{\matr  W_n}^{n \times n} & \overbrace{\vec 0}^{n \times 1} \\ \underbrace{\vec 0^\myT}_{1 \times n} & \underbrace{w_{n+1}}_{1 \times 1} \end{bmatrix}
\\ &=
\begin{bmatrix} \overbrace{\matr X_n^\myT}^{k \times n} & \overbrace{\vec x_{n+1}}^{k \times 1} \end{bmatrix}
\begin{bmatrix} \overbrace{\matr  W_n}^{n \times n} & \overbrace{\vec 0}^{n \times 1} \\ \underbrace{\vec 0^\myT}_{1 \times n} & \underbrace{w_{n+1}}_{1 \times 1} \end{bmatrix}
\\ &=
\begin{bmatrix} \matr X_n^\myT \matr W_n + \vec x_{n+1} \vec 0^\myT & \matr X_n^\myT \vec 0 + w_{n+1} \vec x_{n+1} \end{bmatrix}
\\ &=
\begin{bmatrix} \matr X_n^\myT \matr W_n & w_{n+1} \vec x_{n+1} \end{bmatrix}
\\ &=
\begin{bmatrix} \underbrace{\matr G_{n}}_{k \times n} & \underbrace{w_{n+1} \vec x_{n+1}}_{k\times 1} \end{bmatrix},
\end{align} %]]></script>

<p>where</p>

<script type="math/tex; mode=display">\begin{align}
\matr G_{n+1} \in \mathbb R^{k \times (n+1)}.
\end{align}</script>

<p>In the next step, let us evaluate <script type="math/tex">\matr A_{n+1}</script> from Eq. \eqref{eq:Ap1}:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\matr A_{n+1} &= \matr G_{n+1} \begin{bmatrix} \matr X_n \\ \vec x_{n+1}^\myT \end{bmatrix} + \lambda \matr I \\
&= \begin{bmatrix} \underbrace{\matr G_{n}}_{k \times n} & \underbrace{w_{n+1} \vec x_{n+1}}_{k\times 1} \end{bmatrix} \begin{bmatrix} \overbrace{\matr X_n}^{n \times k} \\ \underbrace{\vec x_{n+1}^\myT}_{1 \times k} \end{bmatrix} + \lambda \matr I \\
&= \matr G_{n} \matr X_n + w_{n+1} \vec x_{n+1} \vec x_{n+1}^\myT+ \lambda \matr I \\
&= \underbrace{\matr G_{n} \matr X_n  + \lambda \matr I}_{=\matr A_n} + w_{n+1} \vec x_{n+1} \vec x_{n+1}^\myT \\
&= \underbrace{\matr A_n}_{k\times k} + \underbrace{w_{n+1} \vec x_{n+1} \vec x_{n+1}^\myT}_{k\times k}
\end{align} %]]></script>

<p>Since we have to compute the inverse of <script type="math/tex">\matr A_{n+1}</script>, it might be helpful to find an incremental formulation, since the inverse is costly to compute. In this case, the Sherman-Morrison formula can help us:</p>

<script type="math/tex; mode=display">\begin{align}
\big(\matr A +  \vec u \vec v^\myT\big)^{-1} = \matr A^{-1} - \frac{\matr A^{-1} \vec u \vec v^\myT \matr A^{-1}} {1+\vec v^\myT A^{-1} \vec u}
\end{align}</script>

<p>In our case this leads to:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\matr A_{n+1}^{-1} &= \matr A_n^{-1} - \frac{\matr A_n^{-1} w_{n+1}\vec x_{n+1} \vec x_{n+1}^\myT \matr A_n^{-1}} {1+w_{n+1} \vec x_{n+1}^\myT A_n^{-1} \vec x_{n+1}} \label{eq:Ap1inv}
\end{align} %]]></script>

<p>Then, we expand Eq. \eqref{eq:Bp1}:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\vec b_{n+1} &= \matr G_{n+1} \begin{bmatrix} \vec y_{n} \\ y_{n+1} \end{bmatrix} \\
&= \begin{bmatrix} \underbrace{\matr G_{n}}_{k \times n} & \underbrace{w_{n+1} \vec x_{n+1}}_{k\times 1} \end{bmatrix}
   \begin{bmatrix} \overbrace{\vec y_{n}}^{n\times 1} \\ \underbrace{y_{n+1}}_{1\times 1} \end{bmatrix}\\
&= \matr G_{n} \vec y_{n} + w_{n+1} \vec x_{n+1} y_{n+1} \\
&= \underbrace{\vec b_{n}}_{k\times 1} + \underbrace{w_{n+1} y_{n+1} \vec x_{n+1}}_{k\times 1} \label{eq:Bp1new}
\end{align} %]]></script>

<p>Now let us insert the results of \eqref{eq:Ap1inv} and \eqref{eq:Bp1new} into Eq. \eqref{eq:phi} and then simplify the expression:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
  \boldsymbol{\theta}_{n+1} &= \matr A_{n+1}^{-1} \vec b_{n+1} \\
  &= \Bigg( \matr A_n^{-1} - \frac{\matr A_n^{-1} w_{n+1}\vec x_{n+1} \vec x_{n+1}^\myT \matr A_n^{-1}} {1+w_{n+1} \vec x_{n+1}^\myT A_n^{-1} \vec x_{n+1}} \Bigg) \cdot
  \Bigg(\vec b_{n} + w_{n+1} y_{n+1} \vec x_{n+1}\Bigg) \\
  &= \underbrace{\matr A_n^{-1} \vec b_{n}}_{=\boldsymbol{\theta}_n} + \matr A_n^{-1} w_{n+1} y_{n+1} \vec x_{n+1} - \frac{\matr A_n^{-1} w_{n+1}\vec x_{n+1} \vec x_{n+1}^\myT \matr A_n^{-1}} {1+w_{n+1} \vec x_{n+1}^\myT A_n^{-1} \vec x_{n+1}} \Bigg(\vec b_{n} + w_{n+1} y_{n+1} \vec x_{n+1}\Bigg) \\
  &= \boldsymbol{\theta}_n + \matr A_n^{-1} w_{n+1} y_{n+1} \vec x_{n+1} - \underbrace{\frac{\matr A_n^{-1} w_{n+1}\vec x_{n+1} } {1+w_{n+1} \vec x_{n+1}^\myT A_n^{-1} \vec x_{n+1}}}_{=\mydelta_{n+1}} \vec x_{n+1}^\myT \matr A_n^{-1} \Bigg(\vec b_{n} + w_{n+1} y_{n+1} \vec x_{n+1}\Bigg) \\
  &= \boldsymbol{\theta}_n + \matr A_n^{-1} w_{n+1} y_{n+1} \vec x_{n+1} - \mydelta_{n+1} \vec x_{n+1}^\myT \matr A_n^{-1} \Bigg(\vec b_{n} + w_{n+1} y_{n+1} \vec x_{n+1}\Bigg) \\
  &= \boldsymbol{\theta}_n + \matr A_n^{-1} w_{n+1} y_{n+1} \vec x_{n+1} - \mydelta_{n+1} \vec x_{n+1}^\myT \matr A_n^{-1} \vec b_{n} -\mydelta_{n+1} \vec x_{n+1}^\myT \matr A_n^{-1} w_{n+1} y_{n+1} \vec x_{n+1} \\
  &= \boldsymbol{\theta}_n + y_{n+1} w_{n+1} \Big( \matr A_n^{-1} \vec x_{n+1} -\mydelta_{n+1} \vec x_{n+1}^\myT \matr A_n^{-1} \vec x_{n+1} \Big) - \mydelta_{n+1} \vec x_{n+1}^\myT \underbrace{\matr A_n^{-1} \vec b_{n} }_{=\boldsymbol{\theta}_{n}} \\
  &= \boldsymbol{\theta}_n + y_{n+1} w_{n+1} \Big( \matr A_n^{-1} -\mydelta_{n+1} \vec x_{n+1}^\myT \matr A_n^{-1}  \Big) \vec x_{n+1} - \mydelta_{n+1} \vec x_{n+1}^\myT \boldsymbol{\theta}_{n}. \label{eq:areWeDone} \\
\end{align} %]]></script>

<p>Note that we used the definition</p>

<script type="math/tex; mode=display">\begin{align}
\mydelta_{n+1} = \frac{\matr A_n^{-1} w_{n+1}\vec x_{n+1} } {1+w_{n+1} \vec x_{n+1}^\myT A_n^{-1} \vec x_{n+1}}, \label{eq:deltaa} \\
\mydelta_{n+1} \in \mathbb{R}^{k},
\end{align}</script>

<p>to make our equation look simpler.
Although we did a few rearrangements, it seems like Eq. \eqref{eq:areWeDone} cannot be simplified further. However, with a small trick we can actually find a nicer solution. For this purpose, let us look closer at Eq. \eqref{eq:deltaa} and play with it a little:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\mydelta_{n+1} &= \frac{\matr A_n^{-1} w_{n+1}\vec x_{n+1} } {1+w_{n+1} \vec x_{n+1}^\myT A_n^{-1} \vec x_{n+1}} \\
\mydelta_{n+1} \big({1+w_{n+1} \vec x_{n+1}^\myT A_n^{-1} \vec x_{n+1}} \big) &= \matr A_n^{-1} w_{n+1}\vec x_{n+1}\\
\mydelta_{n+1} + \mydelta_{n+1}  w_{n+1} \vec x_{n+1}^\myT A_n^{-1} \vec x_{n+1} &= \matr A_n^{-1} w_{n+1}\vec x_{n+1} \\
\mydelta_{n+1} &= \matr A_n^{-1} w_{n+1}\vec x_{n+1} - \mydelta_{n+1}  w_{n+1} \vec x_{n+1}^\myT \matr A_n^{-1} \vec x_{n+1} \\
\mydelta_{n+1} &= w_{n+1} \Big( \matr A_n^{-1} - \mydelta_{n+1} \vec x_{n+1}^\myT \matr A_n^{-1} \Big) \vec x_{n+1} \label{delta-simple}
\end{align} %]]></script>

<p>Interestingly, we can find the RHS of Eq. \eqref{delta-simple} also in Eq. \eqref{eq:areWeDone}. If we use above relation, we can therefore simplify  \eqref{eq:areWeDone} significantly:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\boldsymbol{\theta}_{n+1} &= \boldsymbol{\theta}_n + y_{n+1} w_{n+1} \Big( \matr A_n^{-1} -\mydelta_{n+1} \vec x_{n+1}^\myT \matr A_n^{-1}  \Big) \vec x_{n+1} - \mydelta_{n+1} \vec x_{n+1}^\myT \boldsymbol{\theta}_{n} \\
&= \boldsymbol{\theta}_n + y_{n+1} \mydelta_{n+1} - \mydelta_{n+1} \vec x_{n+1}^\myT \boldsymbol{\theta}_{n} \\
&= \boldsymbol{\theta}_n + \big(y_{n+1} - \vec x_{n+1}^\myT \boldsymbol{\theta}_{n} \big) \mydelta_{n+1}
\end{align} %]]></script>

<p>This means that the above update rule performs some step in the parameter space, which is given by <script type="math/tex">\mydelta_{n+1}</script> which again is scaled by the prediction error for the new point <script type="math/tex">y_{n+1} - \vec x_{n+1}^\myT \boldsymbol{\theta}_{n}</script>. If the prediction error is large, the step taken will also be large. If the prediction error for the new point is <script type="math/tex">0</script> then the parameter vector remains unaltered.</p>

<p>Let us summarize our findings in an algorithmic description of the recursive weighted least squares algorithm:</p>

      <footer class="entry-meta">
        <span class="entry-tags"></span>
        
        <span class="author vcard"><span class="fn">Markus Thill</span></span>
        <div class="social-share">
  <ul class="socialcount socialcount-small inline-list">
    <li class="facebook"><a href="https://www.facebook.com/sharer/sharer.php?u=https://MarkusThill.github.io/derivation-of-a-weighted-recursive-least-squares-estimator/" title="Share on Facebook"><span class="count"><i class="fa fa-facebook-square"></i> Like</span></a></li>
    <li class="twitter"><a href="https://twitter.com/intent/tweet?text=https://MarkusThill.github.io/derivation-of-a-weighted-recursive-least-squares-estimator/" title="Share on Twitter"><span class="count"><i class="fa fa-twitter-square"></i> Tweet</span></a></li>
    <li class="googleplus"><a href="https://plus.google.com/share?url=https://MarkusThill.github.io/derivation-of-a-weighted-recursive-least-squares-estimator/" title="Share on Google Plus"><span class="count"><i class="fa fa-google-plus-square"></i> +1</span></a></li>
  </ul>
</div><!-- /.social-share -->

      </footer>
    </div><!-- /.entry-content -->
    <div class="read-more">
  <div class="read-more-header">
    <a href="https://MarkusThill.github.io/markus" class="read-more-btn">About the Author</a>
  </div><!-- /.read-more-header -->
  <div class="read-more-content author-info">
    <h3>Markus Thill</h3>
    <div class="author-container">
      <img class="author-img" src="https://MarkusThill.github.io/images/avatar.jpg" alt="Markus Thill" />
      <div class="author-bio">I studied computer engineering (B.Sc.) and Automation & IT (M.Eng.). Generally, I am interested in machine learning (ML) approaches (in the broadest sense), but particularly in the fields of time series analysis, anomaly detection, Reinforcement Learning (e.g. for board games), Deep Learning (DL) and incremental (on-line) learning procedures. </div>
    </div>
    <div class="author-share">
      <ul class="list-inline social-buttons">
        
          <li><a href="https://github.com/markusthill" target="_blank"><i class="fa fa-github fa-fw"></i></a></li>
        
          <li><a href="https://www.linkedin.com/in/markus-thill-a4991090/" target="_blank"><i class="fa fa-linkedin fa-fw"></i></a></li>
        
      </ul>
      
        <a aria-label="Follow @MarkusThill on GitHub" data-size="large" href="https://github.com/MarkusThill" class="github-button">Follow @MarkusThill</a>
      
      <br>
      
    </div>
  </div>
</div>

    <section id="disqus_thread"></section><!-- /#disqus_thread -->
    <div class="read-more">
  
    <div class="read-more-header">
      <a href="https://MarkusThill.github.io/gaussian-distribution-with-a-diagonal-covariance-matrix/" class="read-more-btn">Read More</a>
    </div><!-- /.read-more-header -->
    <div class="read-more-content">
      <h3><a href="https://MarkusThill.github.io/deriving-a-closed-form-solution-of-the-fibonacci-sequence/" title="Deriving a Closed-Form Solution of the Fibonacci Sequence using the Z-Transform">Deriving a Closed-Form Solution of the Fibonacci Sequence using the Z-Transform</a></h3>
      <p>The Fibonacci sequence might be one of the most famous sequences in the field of mathmatics and computer science. Already high school stu...&hellip; <a href="https://MarkusThill.github.io/deriving-a-closed-form-solution-of-the-fibonacci-sequence/">Continue reading</a></p>
    </div><!-- /.read-more-content -->
  
  <div class="read-more-list">
    
      <div class="list-item">
        <h4><a href="https://MarkusThill.github.io/gaussian-distribution-with-a-diagonal-covariance-matrix/" title="Gaussian Distribution With a Diagonal Covariance Matrix">Gaussian Distribution With a Diagonal Covariance Matrix</a></h4>
        <span>Published on May 04, 2019</span>
      </div><!-- /.list-item -->
    
      <div class="list-item">
        <h4><a href="https://MarkusThill.github.io/conways-game-of-life/" title="Conway's Game of Life">Conway's Game of Life</a></h4>
        <span>Published on April 13, 2019</span>
      </div><!-- /.list-item -->
    
  </div><!-- /.read-more-list -->
</div><!-- /.read-more -->
  </article>
</div><!-- /#main -->

<script type="text/javascript" src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script type="text/javascript">window.jQuery || document.write('<script type="text/javascript" src="https://MarkusThill.github.io/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script type="text/javascript" src="https://MarkusThill.github.io/assets/js/scripts.min.js"></script>
<script type="text/javascript" async defer id="github-bjs" src="https://buttons.github.io/buttons.js"></script>
<script type="text/javascript">!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^https:/.test(d.location)?'https':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>



<!-- Asynchronous Google Analytics snippet -->
<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-113918188-1', 'auto');
  ga('require', 'linkid', 'linkid.js');
  ga('send', 'pageview');
</script>



    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'markusthill-github-io'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function () {
            var s = document.createElement('script'); s.async = true;
            s.type = 'text/javascript';
            s.src = '//' + disqus_shortname + '.disqus.com/count.js';
            (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
        }());
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>




<script type="text/javascript">
    sharing();
</script>



<div class="footer-wrapper">
  <footer role="contentinfo">
    <span>&copy; 2019 Markus Thill. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="https://github.com/aron-bordin/neo-hpstr-jekyll-theme" rel="nofollow">Neo-HPSTR Theme</a>.</span>

  </footer>
</div><!-- /.footer-wrapper -->

</body>
</html>
