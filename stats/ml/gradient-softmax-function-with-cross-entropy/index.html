<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<!--<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>-->
<!--<script type="text/x-mathjax-config">MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "AMS"} } });</script>-->
<head>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script type="text/x-mathjax-config">MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "AMS"} } });</script>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
<script>
  function resizeIframe(obj) {
    obj.style.height = obj.contentWindow.document.body.scrollHeight + 'px';
  }
</script>

<meta charset="utf-8">
<title>Gradient of the Softmax Function with Cross-Entropy Loss &#8211; ML & Stats</title>
<meta name="description" content="Describe your website here.">
<meta name="keywords" content="">



<!-- Open Graph -->
<meta property="og:locale" content="en">
<meta property="og:type" content="article">
<meta property="og:title" content="Gradient of the Softmax Function with Cross-Entropy Loss">
<meta property="og:description" content="Describe your website here.">
<meta property="og:url" content="https://MarkusThill.github.io/stats/ml/gradient-softmax-function-with-cross-entropy/">
<meta property="og:site_name" content="ML & Stats">
<meta property="og:image" content="https://MarkusThill.github.io/images/antoine-dautry-428776.jpg">






<link rel="canonical" href="https://MarkusThill.github.io/stats/ml/gradient-softmax-function-with-cross-entropy/">
<link href="https://MarkusThill.github.io/feed.xml" type="application/atom+xml" rel="alternate" title="ML & Stats Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no"/>

<!-- For all browsers -->
<link rel="stylesheet" href="https://MarkusThill.github.io/assets/css/main.css">
<link rel="stylesheet" href="https://MarkusThill.github.io/assets/css/jquery.mmenu.all.css">
<link rel="stylesheet" href="https://MarkusThill.github.io/assets/css/jquery.floating-social-share.min.css">
<!-- Webfonts -->
<link href="//fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic" rel="stylesheet" type="text/css">

<meta http-equiv="cleartype" content="on">

<!-- Load Modernizr -->
<script type="text/javascript" src="https://MarkusThill.github.io/assets/js/vendor/modernizr-2.6.2.custom.min.js"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="https://MarkusThill.github.io/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="https://MarkusThill.github.io/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="https://MarkusThill.github.io/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="https://MarkusThill.github.io/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="https://MarkusThill.github.io/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://MarkusThill.github.io/images/apple-touch-icon-144x144-precomposed.png">




<!--<link rel="stylesheet" type="text/css" href="https://cdn.rawgit.com/dreampulse/computer-modern-web-font/master/fonts.css">-->
<link rel="stylesheet" href="/fonts/cmun-serif.css"></link>

<!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Gradient of the Softmax Function with Cross-Entropy Loss | ML &amp; Stats</title>
<meta name="generator" content="Jekyll v3.8.6" />
<meta property="og:title" content="Gradient of the Softmax Function with Cross-Entropy Loss" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="In practice, the so called softmax function is often used for the last layer of a neural network, when several output units are required, in order to squash all outputs in a range of in a way that all outputs sum up to one. A typical application is classification where each output could indicate the probability of the input-vector belonging to a corresponding class. When learning the weights of the neural network using the classical backpropagation algorithm, we need to compute the gradient of the loss function. In the following we show how to compute the gradient of a softmax function for the cross entropy loss, if the softmax function is used in the output of the neural network." />
<meta property="og:description" content="In practice, the so called softmax function is often used for the last layer of a neural network, when several output units are required, in order to squash all outputs in a range of in a way that all outputs sum up to one. A typical application is classification where each output could indicate the probability of the input-vector belonging to a corresponding class. When learning the weights of the neural network using the classical backpropagation algorithm, we need to compute the gradient of the loss function. In the following we show how to compute the gradient of a softmax function for the cross entropy loss, if the softmax function is used in the output of the neural network." />
<link rel="canonical" href="https://markusthill.github.io/stats/ml/gradient-softmax-function-with-cross-entropy/" />
<meta property="og:url" content="https://markusthill.github.io/stats/ml/gradient-softmax-function-with-cross-entropy/" />
<meta property="og:site_name" content="ML &amp; Stats" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2017-09-07T19:29:40+02:00" />
<script type="application/ld+json">
{"description":"In practice, the so called softmax function is often used for the last layer of a neural network, when several output units are required, in order to squash all outputs in a range of in a way that all outputs sum up to one. A typical application is classification where each output could indicate the probability of the input-vector belonging to a corresponding class. When learning the weights of the neural network using the classical backpropagation algorithm, we need to compute the gradient of the loss function. In the following we show how to compute the gradient of a softmax function for the cross entropy loss, if the softmax function is used in the output of the neural network.","headline":"Gradient of the Softmax Function with Cross-Entropy Loss","dateModified":"2017-09-07T19:29:40+02:00","datePublished":"2017-09-07T19:29:40+02:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://markusthill.github.io/stats/ml/gradient-softmax-function-with-cross-entropy/"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://markusthill.github.io/images/logo.png"}},"url":"https://markusthill.github.io/stats/ml/gradient-softmax-function-with-cross-entropy/","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

</head>

<body id="post" class="feature">

<!--[if lt IE 9]><div class="upgrade"><strong><a href="https://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->



<div class="header-menu header-menu-top">
    <ul class="header-item-container">
      <li class="header-item-title header-toggle "><a href="#menu"><h2><i class="fa fa-bars"></i></h2></a></li>
      <li class="header-item-title">
        <a href="https://MarkusThill.github.io/">
          
            <img class="logo" src="https://MarkusThill.github.io/images/logo.png" alt="ML & Stats">
          
          <a href="https://MarkusThill.github.io/" class="title"> ML & Stats</a>
        </a>
      </li>
      
        
        

        
            
                <li class="header-item "><a href="https://MarkusThill.github.io/posts"><h3>Posts</h3></a></li>
            
        
      
        
        

        
          <li class="header-item "><a href="https://MarkusThill.github.io/categories"><h3>Categories</h3></a>
            <ul class="header-submenu">
              
                
                  <li class="sub-item"><a href="https://MarkusThill.github.io/categories/#Electronics">Electronics</a></li>
              
                
                  <li class="sub-item"><a href="https://MarkusThill.github.io/categories/#ML">ML</a></li>
              
                
                  <li class="sub-item"><a href="https://MarkusThill.github.io/categories/#Math">Math</a></li>
              
                
                  <li class="sub-item"><a href="https://MarkusThill.github.io/categories/#Programming">Programming</a></li>
              
                
                  <li class="sub-item"><a href="https://MarkusThill.github.io/categories/#Stats">Stats</a></li>
              
                
                  <li class="sub-item"><a href="https://MarkusThill.github.io/categories/#Template">Template</a></li>
              
                
                  <li class="sub-item"><a href="https://MarkusThill.github.io/categories/#Vector Algebra">Vector Algebra</a></li>
              
            </ul>
          </li>
        
      
        
        

        
            
                <li class="header-item "><a href="https://MarkusThill.github.io/tags"><h3>Tags</h3></a></li>
            
        
      
        
        

        
            
                <li class="header-item "><a href="https://MarkusThill.github.io/markus"><h3>About</h3></a></li>
            
        
      
        
        

        
            
                <li class="header-item "><a href="https://MarkusThill.github.io/"><h3>Home</h3></a></li>
            
        
      
      <li class="header-item"><a href="https://MarkusThill.github.io/search"><h3><i class="fa fa-search"></i></h3></a></li>
    </ul>
  </div>
<div class="entry-header">
  <div class="header-title">
    <div class="header-title-wrap">
      <h1>Gradient of the Softmax Function with Cross-Entropy Loss</h1>
      
        <h2><span class="entry-date date published updated"><time datetime="2017-09-07T19:29:40+02:00">September 07, 2017</time></span></h2>
      

      
        <p class="entry-reading-time">
          <i class="fa fa-clock-o"></i>
          
          Reading time ~1 minute
        </p><!-- /.entry-reading-time -->
      
    </div><!-- /.header-title-wrap -->
  </div><!-- /.header-title -->
</div><!-- /.entry-header -->


<nav id="menu" style="display: none">
  <ul>
    
      
        <li><a href="https://MarkusThill.github.io/"><h3>Home</h3></a></li>
      
    
      
        <li><a href="https://MarkusThill.github.io/markus"><h3>About</h3></a></li>
      
    
      
        <li><a href="https://MarkusThill.github.io/tags"><h3>Tags</h3></a></li>
      
    
      
        <li><a href="https://MarkusThill.github.io/categories"><h3>Categories</h3></a>
          <ul>
            
              
                <li><a href="https://MarkusThill.github.io/categories/#Electronics">Electronics</a></li>
            
              
                <li><a href="https://MarkusThill.github.io/categories/#ML">ML</a></li>
            
              
                <li><a href="https://MarkusThill.github.io/categories/#Math">Math</a></li>
            
              
                <li><a href="https://MarkusThill.github.io/categories/#Programming">Programming</a></li>
            
              
                <li><a href="https://MarkusThill.github.io/categories/#Stats">Stats</a></li>
            
              
                <li><a href="https://MarkusThill.github.io/categories/#Template">Template</a></li>
            
              
                <li><a href="https://MarkusThill.github.io/categories/#Vector Algebra">Vector Algebra</a></li>
            
          </ul>
        </li>
      
    
      
        <li><a href="https://MarkusThill.github.io/posts"><h3>Posts</h3></a></li>
      
    
  </ul>
</nav>




<div id="main" role="main">
  <article class="hentry">
    <div class="entry-content">
        
            <div class="entry-image-index">
              <img src="https://MarkusThill.github.io/images/antoine-dautry-428776.jpg" alt="Gradient of the Softmax Function with Cross-Entropy Loss">
              <div class="image-credit">Image source: <a target="_blank" href="https://unsplash.com">Photo by Antoine Dautry on Unsplash</a></div><!-- /.image-credit -->
            </div>
        
      <h1 class="post-title entry-title">Gradient of the Softmax Function with Cross-Entropy Loss</h1>
      <p>In practice, the so called softmax function is often used for the last layer of a neural network, when several output units are required, in order to squash all outputs in a range of <script type="math/tex">[0,1]</script> in a way that all outputs sum up to one. A typical application is classification where each output could indicate the probability of the input-vector belonging to a corresponding class. When learning the weights of the neural network using the classical backpropagation algorithm, we need to compute the gradient of the loss function. In the following we show how to compute the gradient of a softmax function for the cross entropy loss, if the softmax function is used in the output of the neural network.</p>

<!--more-->

<p>The general softmax function for a unit <script type="math/tex">z_j</script> is defined as:
\begin{eqnarray}
o_j = \frac{\mbox{e}^{z_j}}{\sum_k \mbox{e}^{z_k}},
\end{eqnarray}
where <script type="math/tex">k</script> iterates over all output units.
The cross-entropy loss for a softmax unit with <script type="math/tex">p</script> output units <script type="math/tex">o_j</script> and targets <script type="math/tex">y^*_j</script> is defined as:</p>

<script type="math/tex; mode=display">\begin{eqnarray}
E=-\sum_j^{p} y^*_j\cdot \mbox{log}(o_j)
\end{eqnarray}</script>

<p>In order to compute the gradient of <script type="math/tex">E</script> with respect to <script type="math/tex">z_i</script>, we can start with:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\frac{\partial E}{\partial z_i}&=- \sum_j^{p} y^*_j\cdot  \frac{\partial}{\partial z_i}\mbox{log}(o_j)\\
&=- \sum_{j \neq i}^{p} y^*_j\cdot  \frac{\partial}{\partial z_i}\mbox{log}(o_j) - y^*_i\cdot  \frac{\partial}{\partial z_i}\mbox{log}(o_i)
\label{eq:partialSoftmax}
\end{align} %]]></script>

<p>Now we compute both partial derivatives of <script type="math/tex">o_j</script> and <script type="math/tex">o_i</script>, which lead to different results:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
  \frac{\partial}{\partial z_i} o_j &= \frac{\partial}{\partial z_i} \frac{\mbox{e}^{z_j}}{\sum_k \mbox{e}^{z_k}}\\
  &= \mbox{e}^{z_j} \frac{\partial}{\partial z_i} \Bigg(\sum_k \mbox{e}^{z_k} \Bigg)^{-1}\\
  &= -\mbox{e}^{z_j} \Bigg(\sum_k \mbox{e}^{z_k} \Bigg)^{-2} \mbox{e}^{z_i}\\
  &= -o_j \cdot o_i
  \label{eq:partialOj}
\end{align} %]]></script>

<p>and</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
  \frac{\partial}{\partial z_i} o_i &= \frac{\partial}{\partial z_i} \frac{\mbox{e}^{z_i}}{\sum_k \mbox{e}^{z_k}} \\
  &= \frac{\mbox{e}^{z_i}}{\sum_k \mbox{e}^{z_k}} + \mbox{e}^{z_i}\frac{\partial}{\partial z_i} \frac{1}{\sum_k \mbox{e}^{z_k}}\\
  &= \frac{\mbox{e}^{z_i}}{\sum_k \mbox{e}^{z_k}} - \mbox{e}^{z_i} \Big(\sum_k \mbox{e}^{z_k}\Big)^{-2} \mbox{e}^{z_i}\\
  &= o_i - o_i^2
  \label{eq:partialOi}
\end{align} %]]></script>

<p>With  these 2 partial derivatives we can now simplify Eq.\eqref{eq:partialSoftmax}:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\frac{\partial E}{\partial z_i}&=-\sum_{j \neq i}^{p} y^*_j\cdot  \frac{\partial}{\partial z_i}\mbox{log}(o_j) - y^*_i\cdot  \frac{\partial}{\partial z_i}\mbox{log}(o_i)\\
&= -\sum_{j \neq i}^{p} y^*_j \frac{1}{o_j} \frac{\partial}{\partial z_i}o_j - y^*_i \frac{1}{o_i} \frac{\partial}{\partial z_i}o_i
\label{eq:partialSoftmax2}
\end{align} %]]></script>

<p>We insert \eqref{eq:partialOj} and \eqref{eq:partialOi} into \eqref{eq:partialSoftmax2}:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\frac{\partial E}{\partial z_i}
&= \sum_{j \neq i}^{p} y^*_j \frac{1}{o_j} o_j \cdot o_i - y^*_i \frac{1}{o_i} (o_i - o_i^2)\\
&= \sum_{j \neq i}^{p} y^*_j   o_i - y^*_i  (1 - o_i)\\
&= o_i\sum_{j \neq i}^{p} y^*_j    - y^*_i   + y^*_i  o_i \\
&= o_i \underbrace{\sum_{j =1}^{p} y^*_j }_{=1}   - y^*_i  \\
&= o_i  - y^*_i
\end{align} %]]></script>

      <footer class="entry-meta">
        <span class="entry-tags"></span>
        
        <span class="author vcard"><span class="fn">Markus Thill</span></span>
        <div class="social-share">
  <ul class="socialcount socialcount-small inline-list">
    <li class="facebook"><a href="https://www.facebook.com/sharer/sharer.php?u=https://MarkusThill.github.io/stats/ml/gradient-softmax-function-with-cross-entropy/" title="Share on Facebook"><span class="count"><i class="fa fa-facebook-square"></i> Like</span></a></li>
    <li class="twitter"><a href="https://twitter.com/intent/tweet?text=https://MarkusThill.github.io/stats/ml/gradient-softmax-function-with-cross-entropy/" title="Share on Twitter"><span class="count"><i class="fa fa-twitter-square"></i> Tweet</span></a></li>
    <li class="googleplus"><a href="https://plus.google.com/share?url=https://MarkusThill.github.io/stats/ml/gradient-softmax-function-with-cross-entropy/" title="Share on Google Plus"><span class="count"><i class="fa fa-google-plus-square"></i> +1</span></a></li>
  </ul>
</div><!-- /.social-share -->

      </footer>
    </div><!-- /.entry-content -->
    <div class="read-more">
  <div class="read-more-header">
    <a href="https://MarkusThill.github.io/markus" class="read-more-btn">About the Author</a>
  </div><!-- /.read-more-header -->
  <div class="read-more-content author-info">
    <h3>Markus Thill</h3>
    <div class="author-container">
      <img class="author-img" src="https://MarkusThill.github.io/images/avatar.jpg" alt="Markus Thill" />
      <div class="author-bio">I studied computer engineering (B.Sc.) and Automation & IT (M.Eng.). Generally, I am interested in machine learning (ML) approaches (in the broadest sense), but particularly in the fields of time series analysis, anomaly detection, Reinforcement Learning (e.g. for board games), Deep Learning (DL) and incremental (on-line) learning procedures. </div>
    </div>
    <div class="author-share">
      <ul class="list-inline social-buttons">
        
          <li><a href="https://github.com/markusthill" target="_blank"><i class="fa fa-github fa-fw"></i></a></li>
        
          <li><a href="https://www.linkedin.com/in/markus-thill-a4991090/" target="_blank"><i class="fa fa-linkedin fa-fw"></i></a></li>
        
      </ul>
      
        <a aria-label="Follow @MarkusThill on GitHub" data-size="large" href="https://github.com/MarkusThill" class="github-button">Follow @MarkusThill</a>
      
      <br>
      
    </div>
  </div>
</div>

    <section id="disqus_thread"></section><!-- /#disqus_thread -->
    <div class="read-more">
  
    <div class="read-more-header">
      <a href="https://MarkusThill.github.io/mahalanbis-chi-squared/" class="read-more-btn">Read More</a>
    </div><!-- /.read-more-header -->
    <div class="read-more-content">
      <h3><a href="https://MarkusThill.github.io/deriving-a-closed-form-solution-of-the-fibonacci-sequence/" title="Deriving a Closed-Form Solution of the Fibonacci Sequence using the Z-Transform">Deriving a Closed-Form Solution of the Fibonacci Sequence using the Z-Transform</a></h3>
      <p>The Fibonacci sequence might be one of the most famous sequences in the field of mathmatics and computer science. Already high school stu...&hellip; <a href="https://MarkusThill.github.io/deriving-a-closed-form-solution-of-the-fibonacci-sequence/">Continue reading</a></p>
    </div><!-- /.read-more-content -->
  
  <div class="read-more-list">
    
      <div class="list-item">
        <h4><a href="https://MarkusThill.github.io/derivation-of-a-weighted-recursive-least-squares-estimator/" title="Derivation of a Weighted Recursive Linear Least Squares Estimator">Derivation of a Weighted Recursive Linear Least Squares Estimator</a></h4>
        <span>Published on May 05, 2019</span>
      </div><!-- /.list-item -->
    
      <div class="list-item">
        <h4><a href="https://MarkusThill.github.io/gaussian-distribution-with-a-diagonal-covariance-matrix/" title="Gaussian Distribution With a Diagonal Covariance Matrix">Gaussian Distribution With a Diagonal Covariance Matrix</a></h4>
        <span>Published on May 04, 2019</span>
      </div><!-- /.list-item -->
    
  </div><!-- /.read-more-list -->
</div><!-- /.read-more -->
  </article>
</div><!-- /#main -->

<script type="text/javascript" src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script type="text/javascript">window.jQuery || document.write('<script type="text/javascript" src="https://MarkusThill.github.io/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script type="text/javascript" src="https://MarkusThill.github.io/assets/js/scripts.min.js"></script>
<script type="text/javascript" async defer id="github-bjs" src="https://buttons.github.io/buttons.js"></script>
<script type="text/javascript">!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^https:/.test(d.location)?'https':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>



<!-- Asynchronous Google Analytics snippet -->
<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-113918188-1', 'auto');
  ga('require', 'linkid', 'linkid.js');
  ga('send', 'pageview');
</script>



    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'markusthill-github-io'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function () {
            var s = document.createElement('script'); s.async = true;
            s.type = 'text/javascript';
            s.src = '//' + disqus_shortname + '.disqus.com/count.js';
            (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
        }());
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>




<script type="text/javascript">
    sharing();
</script>



<div class="footer-wrapper">
  <footer role="contentinfo">
    <span>&copy; 2019 Markus Thill. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="https://github.com/aron-bordin/neo-hpstr-jekyll-theme" rel="nofollow">Neo-HPSTR Theme</a>.</span>

  </footer>
</div><!-- /.footer-wrapper -->

</body>
</html>
