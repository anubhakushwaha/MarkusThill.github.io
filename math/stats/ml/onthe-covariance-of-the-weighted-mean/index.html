<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<!--<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>-->
<!--<script type="text/x-mathjax-config">MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "AMS"} } });</script>-->
<head>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script type="text/x-mathjax-config">MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "AMS"} } });</script>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
<script>
  function resizeIframe(obj) {
    obj.style.height = obj.contentWindow.document.body.scrollHeight + 'px';
  }
</script>

<meta charset="utf-8">
<title>The Covariance of weighted Means &#8211; ML & Stats</title>
<meta name="description" content="Describe your website here.">
<meta name="keywords" content="Online, Gaussians, Covariances, Maximum Likelihood Estimation">



<!-- Open Graph -->
<meta property="og:locale" content="en">
<meta property="og:type" content="article">
<meta property="og:title" content="The Covariance of weighted Means">
<meta property="og:description" content="Describe your website here.">
<meta property="og:url" content="https://MarkusThill.github.io/math/stats/ml/onthe-covariance-of-the-weighted-mean/">
<meta property="og:site_name" content="ML & Stats">
<meta property="og:image" content="https://MarkusThill.github.io/images/stats.jpg">






<link rel="canonical" href="https://MarkusThill.github.io/math/stats/ml/onthe-covariance-of-the-weighted-mean/">
<link href="https://MarkusThill.github.io/feed.xml" type="application/atom+xml" rel="alternate" title="ML & Stats Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no"/>

<!-- For all browsers -->
<link rel="stylesheet" href="https://MarkusThill.github.io/assets/css/main.css">
<link rel="stylesheet" href="https://MarkusThill.github.io/assets/css/jquery.mmenu.all.css">
<link rel="stylesheet" href="https://MarkusThill.github.io/assets/css/jquery.floating-social-share.min.css">
<!-- Webfonts -->
<link href="//fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic" rel="stylesheet" type="text/css">

<meta http-equiv="cleartype" content="on">

<!-- Load Modernizr -->
<script type="text/javascript" src="https://MarkusThill.github.io/assets/js/vendor/modernizr-2.6.2.custom.min.js"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="https://MarkusThill.github.io/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="https://MarkusThill.github.io/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="https://MarkusThill.github.io/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="https://MarkusThill.github.io/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="https://MarkusThill.github.io/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://MarkusThill.github.io/images/apple-touch-icon-144x144-precomposed.png">




<!--<link rel="stylesheet" type="text/css" href="https://cdn.rawgit.com/dreampulse/computer-modern-web-font/master/fonts.css">-->
<link rel="stylesheet" href="/fonts/cmun-serif.css"></link>

<!-- Begin Jekyll SEO tag v2.6.1 -->
<title>The Covariance of weighted Means | ML &amp; Stats</title>
<meta name="generator" content="Jekyll v3.8.6" />
<meta property="og:title" content="The Covariance of weighted Means" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="This post is part 3 of a series of five articles: Online Maximum Likelihood Estimation of (multivariate) Gaussian Distributions Online Estimation of Weighted Sample Mean and Coviarance Matrix The Covariance of weighted Means Memory of the exponentially decaying Estimator for Mean and Covariance Matrix Online Estimation of the Inverse Covariance Matrix \( \def\myX{\mathbf{x}} \def\myM{\mathbf{M}} \def\myY{\mathbf{y}} \def\mySigma{\mathbf{\Sigma}} \def\myM{\mathbf{M}} \def\myT{\mathsf{T}} \) Typically, when computes the conventional sample mean, the covariances of the sample mean vector (note: here we are actually talking about the covariance matrix for the sample mean and not the estimated covariance matrix of the sample itself. This is somewhat similar to the computation of the standard error of the mean.) will tend to zero as the sample size grows larger. Similarly to the standard error of the mean which can be expressed as the expected covariance matrix is which indicates, that for a sufficiently large sample , the estimated mean will most likely be rather close (under the typical conditions) to the real mean of the underlying distribution." />
<meta property="og:description" content="This post is part 3 of a series of five articles: Online Maximum Likelihood Estimation of (multivariate) Gaussian Distributions Online Estimation of Weighted Sample Mean and Coviarance Matrix The Covariance of weighted Means Memory of the exponentially decaying Estimator for Mean and Covariance Matrix Online Estimation of the Inverse Covariance Matrix \( \def\myX{\mathbf{x}} \def\myM{\mathbf{M}} \def\myY{\mathbf{y}} \def\mySigma{\mathbf{\Sigma}} \def\myM{\mathbf{M}} \def\myT{\mathsf{T}} \) Typically, when computes the conventional sample mean, the covariances of the sample mean vector (note: here we are actually talking about the covariance matrix for the sample mean and not the estimated covariance matrix of the sample itself. This is somewhat similar to the computation of the standard error of the mean.) will tend to zero as the sample size grows larger. Similarly to the standard error of the mean which can be expressed as the expected covariance matrix is which indicates, that for a sufficiently large sample , the estimated mean will most likely be rather close (under the typical conditions) to the real mean of the underlying distribution." />
<link rel="canonical" href="https://markusthill.github.io/math/stats/ml/onthe-covariance-of-the-weighted-mean/" />
<meta property="og:url" content="https://markusthill.github.io/math/stats/ml/onthe-covariance-of-the-weighted-mean/" />
<meta property="og:site_name" content="ML &amp; Stats" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-01-18T13:41:30+01:00" />
<script type="application/ld+json">
{"description":"This post is part 3 of a series of five articles: Online Maximum Likelihood Estimation of (multivariate) Gaussian Distributions Online Estimation of Weighted Sample Mean and Coviarance Matrix The Covariance of weighted Means Memory of the exponentially decaying Estimator for Mean and Covariance Matrix Online Estimation of the Inverse Covariance Matrix \\( \\def\\myX{\\mathbf{x}} \\def\\myM{\\mathbf{M}} \\def\\myY{\\mathbf{y}} \\def\\mySigma{\\mathbf{\\Sigma}} \\def\\myM{\\mathbf{M}} \\def\\myT{\\mathsf{T}} \\) Typically, when computes the conventional sample mean, the covariances of the sample mean vector (note: here we are actually talking about the covariance matrix for the sample mean and not the estimated covariance matrix of the sample itself. This is somewhat similar to the computation of the standard error of the mean.) will tend to zero as the sample size grows larger. Similarly to the standard error of the mean which can be expressed as the expected covariance matrix is which indicates, that for a sufficiently large sample , the estimated mean will most likely be rather close (under the typical conditions) to the real mean of the underlying distribution.","headline":"The Covariance of weighted Means","dateModified":"2018-01-18T13:41:30+01:00","datePublished":"2018-01-18T13:41:30+01:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://markusthill.github.io/math/stats/ml/onthe-covariance-of-the-weighted-mean/"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://markusthill.github.io/images/logo.png"}},"url":"https://markusthill.github.io/math/stats/ml/onthe-covariance-of-the-weighted-mean/","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

</head>

<body id="post" class="feature">

<!--[if lt IE 9]><div class="upgrade"><strong><a href="https://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->



<div class="header-menu header-menu-top">
    <ul class="header-item-container">
      <li class="header-item-title header-toggle "><a href="#menu"><h2><i class="fa fa-bars"></i></h2></a></li>
      <li class="header-item-title">
        <a href="https://MarkusThill.github.io/">
          
            <img class="logo" src="https://MarkusThill.github.io/images/logo.png" alt="ML & Stats">
          
          <a href="https://MarkusThill.github.io/" class="title"> ML & Stats</a>
        </a>
      </li>
      
        
        

        
            
                <li class="header-item "><a href="https://MarkusThill.github.io/posts"><h3>Posts</h3></a></li>
            
        
      
        
        

        
          <li class="header-item "><a href="https://MarkusThill.github.io/categories"><h3>Categories</h3></a>
            <ul class="header-submenu">
              
                
                  <li class="sub-item"><a href="https://MarkusThill.github.io/categories/#Electronics">Electronics</a></li>
              
                
                  <li class="sub-item"><a href="https://MarkusThill.github.io/categories/#ML">ML</a></li>
              
                
                  <li class="sub-item"><a href="https://MarkusThill.github.io/categories/#Math">Math</a></li>
              
                
                  <li class="sub-item"><a href="https://MarkusThill.github.io/categories/#Programming">Programming</a></li>
              
                
                  <li class="sub-item"><a href="https://MarkusThill.github.io/categories/#Stats">Stats</a></li>
              
                
                  <li class="sub-item"><a href="https://MarkusThill.github.io/categories/#Template">Template</a></li>
              
                
                  <li class="sub-item"><a href="https://MarkusThill.github.io/categories/#Vector Algebra">Vector Algebra</a></li>
              
            </ul>
          </li>
        
      
        
        

        
            
                <li class="header-item "><a href="https://MarkusThill.github.io/tags"><h3>Tags</h3></a></li>
            
        
      
        
        

        
            
                <li class="header-item "><a href="https://MarkusThill.github.io/markus"><h3>About</h3></a></li>
            
        
      
        
        

        
            
                <li class="header-item "><a href="https://MarkusThill.github.io/"><h3>Home</h3></a></li>
            
        
      
      <li class="header-item"><a href="https://MarkusThill.github.io/search"><h3><i class="fa fa-search"></i></h3></a></li>
    </ul>
  </div>
<div class="entry-header">
  <div class="header-title">
    <div class="header-title-wrap">
      <h1>The Covariance of weighted Means</h1>
      
        <h2><span class="entry-date date published updated"><time datetime="2018-01-18T13:41:30+01:00">January 18, 2018</time></span></h2>
      

      
        <p class="entry-reading-time">
          <i class="fa fa-clock-o"></i>
          
          Reading time ~2 minutes
        </p><!-- /.entry-reading-time -->
      
    </div><!-- /.header-title-wrap -->
  </div><!-- /.header-title -->
</div><!-- /.entry-header -->


<nav id="menu" style="display: none">
  <ul>
    
      
        <li><a href="https://MarkusThill.github.io/"><h3>Home</h3></a></li>
      
    
      
        <li><a href="https://MarkusThill.github.io/markus"><h3>About</h3></a></li>
      
    
      
        <li><a href="https://MarkusThill.github.io/tags"><h3>Tags</h3></a></li>
      
    
      
        <li><a href="https://MarkusThill.github.io/categories"><h3>Categories</h3></a>
          <ul>
            
              
                <li><a href="https://MarkusThill.github.io/categories/#Electronics">Electronics</a></li>
            
              
                <li><a href="https://MarkusThill.github.io/categories/#ML">ML</a></li>
            
              
                <li><a href="https://MarkusThill.github.io/categories/#Math">Math</a></li>
            
              
                <li><a href="https://MarkusThill.github.io/categories/#Programming">Programming</a></li>
            
              
                <li><a href="https://MarkusThill.github.io/categories/#Stats">Stats</a></li>
            
              
                <li><a href="https://MarkusThill.github.io/categories/#Template">Template</a></li>
            
              
                <li><a href="https://MarkusThill.github.io/categories/#Vector Algebra">Vector Algebra</a></li>
            
          </ul>
        </li>
      
    
      
        <li><a href="https://MarkusThill.github.io/posts"><h3>Posts</h3></a></li>
      
    
  </ul>
</nav>




<div id="main" role="main">
  <article class="hentry">
    <div class="entry-content">
        
            <div class="entry-image-index">
              <img src="https://MarkusThill.github.io/images/stats.jpg" alt="The Covariance of weighted Means">
              
            </div>
        
      <h1 class="post-title entry-title">The Covariance of weighted Means</h1>
      <p>This post is part 3 of a series of five articles:</p>
<ol>
  <li><a href="/math/stats/ml/online-estimation-of-gaussians/">Online Maximum Likelihood Estimation of (multivariate) Gaussian Distributions</a></li>
  <li><a href="/math/stats/ml/online-estimation-of-weighted-sample-mean-and-coviarance-matrix/">Online Estimation of Weighted Sample Mean and Coviarance Matrix</a></li>
  <li><strong><a href="/math/stats/ml/onthe-covariance-of-the-weighted-mean/">The Covariance of weighted Means</a></strong></li>
  <li><a href="/math/stats/ml/memory-of-an-exponentially-weighted-estimator-of-the-arithmetic-mean-and-covariance-matrix/">Memory of the exponentially decaying Estimator for Mean and Covariance Matrix</a></li>
  <li><a href="/math/stats/ml/online-estimation-of-the-inverse-covariance-matrix/">Online Estimation of the Inverse Covariance Matrix</a></li>
</ol>

<p>\( <br />
  \def\myX{\mathbf{x}}
  \def\myM{\mathbf{M}}
  \def\myY{\mathbf{y}}
  \def\mySigma{\mathbf{\Sigma}}
  \def\myM{\mathbf{M}}
  \def\myT{\mathsf{T}}
\)</p>

<!--- ## Covariance of the weighted Mean -->

<p>Typically, when computes the conventional sample mean, the covariances of the sample mean vector <script type="math/tex">\bar{\myX}_n</script> (note: here we are actually talking about the covariance matrix for the sample mean <script type="math/tex">\bar{\myX}_n</script> and not the estimated covariance matrix of the sample itself. This is somewhat similar to the computation of the standard error of the mean.) will tend to zero as the sample size <script type="math/tex">n</script> grows larger. Similarly to the standard error of the mean which can be expressed as</p>

<script type="math/tex; mode=display">\begin{align}
  \sigma_\bar{X}^2 = \frac{\sigma^2}{n},
\end{align}</script>

<p>the expected covariance matrix <script type="math/tex">\Sigma_\bar{X}</script> is</p>

<script type="math/tex; mode=display">\begin{align}
  \Sigma_\bar{X} = \frac{1}{n} \Sigma,
\end{align}</script>

<p>which indicates, that for a sufficiently large sample <script type="math/tex">n</script>, the estimated mean <script type="math/tex">\bar{\myX}_n</script> will most likely be rather close (under the typical conditions) to the real mean <script type="math/tex">\mathbf \mu_X</script> of the underlying distribution.</p>

<!--more-->

<p>However, if weighted sample means and covariances are computed, this is no longer necessarily the case. As we will see later, in the weighted case, the elements in covariance matrix of the sample mean will not converge towards zero in certain situations, implying that the sample mean will not converge to the real mean. Some variance will remain in the estimation and increasing the sample size will not change this. In such cases, we can say that the estimator has a “limited memory”. This may be undesirable when estimating stationary distributions on the one hand. On the other hand, a limited memory can make sense if certain statistics of the underlying distribution (E.g., the means or variances) change over time (often called concept drift or concept change), since the estimator can then forget about the past and learn to adapt its parameters to the drifting distribution. In order to understand the effects that weighted sample statistics generate, we investigate in this section, how the covariance of weighted means behave in different settings.</p>

<p>Let us first derive a formulation for the covariance of two weighted means <script type="math/tex">\bar{X}_n</script> and <script type="math/tex">\bar{Y}_n</script>, which are computed for the two jointly distributed random variables <script type="math/tex">X</script> and <script type="math/tex">Y</script>. Remember that the covariance of two jointly distributed random variables is defined as:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
  \mbox{cov}(X,Y) &= E[(X - E[X])(Y - E[Y])] \\
                  &= E[X Y] - E[X] E[Y]. \\
\end{align} %]]></script>

<p>Then, the covariance of the two sample means <script type="math/tex">\bar{X}_n</script> and <script type="math/tex">\bar{Y}_n</script> is:</p>

<p><script type="math/tex">% <![CDATA[
\begin{align}
  \mbox{cov}(\bar{X}_n,\bar{Y}_n) &= \mbox{cov} \Bigg(\frac{\sum_{i=1}^{n} w'_i X_i}{\sum_{i=1}^{n} w'_i}, \frac{\sum_{i=1}^{n} w'_i Y_i}{\sum_{i=1}^{n} w'_i}\Bigg) \\
  &= \mbox{cov} \Bigg(\frac{1}{W_n} \sum_{i=1}^{n} w'_i X_i, \frac{1}{W_n} \sum_{i=1}^{n} w'_i Y_i \Bigg) \label{eq:covSampleMeans} \\
\end{align} %]]></script> <!---_ --></p>

<p>with random variables <script type="math/tex">X_i</script> and <script type="math/tex">Y_i</script> and where</p>

<p><script type="math/tex">\begin{align}
  W_n = \sum_{i=1}^{n} w'_i.
\end{align}</script> <!---_ --></p>

<p>Let us assume that all weights are already normalized so that</p>

<p><script type="math/tex">\begin{align}
  w_i = \frac{w'_i}{W_n} = \frac{w'_i}{\sum_{i=1}^{n} w'_i}.
\end{align}</script> <!---_ --></p>

<p>Then Eq. \eqref{eq:covSampleMeans}, simplifies to:</p>

<p><script type="math/tex">% <![CDATA[
\begin{align}
  \mbox{cov}(\bar{X}_n,\bar{Y}_n) &= \mbox{cov} \Bigg(\sum_{i=1}^{n} w_i X_i, \sum_{i=1}^{n} w_i Y_i \Bigg) \\
  &= E\Bigg[\sum_{i=1}^{n} w_i X_i \cdot \sum_{j=1}^{n} w_j Y_j \Bigg] - E[\bar{X}_n] E[\bar{Y}_n] \label{eq:covSampleMeansNormalized} \\
\end{align} %]]></script> <!---_ --></p>

<p>Let the expected values <script type="math/tex">\mu_\bar{X_n} = E[\bar{X}_n]</script> and <script type="math/tex">\mu_\bar{Y_n} = E[\bar{Y}_n]</script> be the real means of the two jointly distributed random variables, so that Eq. \eqref{eq:covSampleMeansNormalized} can be written as:</p>

<p><script type="math/tex">% <![CDATA[
\begin{align}
  \mbox{cov}(\bar{X}_n,\bar{Y}_n) &= E\Bigg[\sum_{i=1}^{n} w_i X_i \cdot \sum_{j=1}^{n} w_j Y_j \Bigg] - \mu_\bar{X_n} \mu_\bar{Y_n} \\
  &= E\Bigg[\sum_{i=1}^{n} \sum_{j=1}^{n} w_i w_j X_i Y_j \Bigg] - \mu_\bar{X_n} \mu_\bar{Y_n} \\
  &= E\Bigg[\sum_{i=1}^{n} w_i^2 X_i Y_j + \sum_{i=1}^{n} \sum_{\substack{j=1\\ j \neq i}}^{n} w_i w_j X_i Y_j \Bigg] - \mu_\bar{X_n} \mu_\bar{Y_n} \label{eq:covSampleMeansNormalized2}
\end{align} %]]></script> <!---_ --></p>

<p>Note that in above Eq. \eqref{eq:covSampleMeansNormalized2}, the original sum was split into two, so that the paired (mutually dependent) data points <script type="math/tex">(X_i, Y_i)</script> share the same sum. All other pairs <script type="math/tex">\{(X_i,Y_j) \ \vert \ i \neq j\}</script> are statistically independent and can be treated differently in the following. With the relation</p>

<script type="math/tex; mode=display">\begin{align}
E[XY] = E[X]E[Y]
\end{align}</script>

<p>for independent random variables <script type="math/tex">X</script> and <script type="math/tex">Y</script>, we get for Eq. \eqref{eq:covSampleMeansNormalized2}:</p>

<p><script type="math/tex">% <![CDATA[
\begin{align}
  \mbox{cov}(\bar{X}_n,\bar{Y}_n) &= E\Bigg[\sum_{i=1}^{n} w_i^2 X_i Y_j + \sum_{i=1}^{n} \sum_{\substack{j=1\\ j \neq i}}^{n} w_i w_j X_i Y_j \Bigg] - \mu_{\bar{X}_n} \mu_{\bar{Y}_n}  \\
  &= E\Bigg[\sum_{i=1}^{n} w_i^2 X_i Y_j \Bigg] + E\Bigg[\sum_{i=1}^{n} \sum_{\substack{j=1\\ j \neq i}}^{n} w_i w_j X_i Y_j \Bigg] - \mu_{\bar{X}_n} \mu_{\bar{Y}_n} \\
  &= \sum_{i=1}^{n} w_i^2 E[X_i Y_j] + \sum_{i=1}^{n} \sum_{\substack{j=1\\ j \neq i}}^{n} w_i w_j E[X_i Y_j] - \mu_{\bar{X}_n} \mu_{\bar{Y}_n} \\
  &= \sum_{i=1}^{n} w_i^2 E[X_i Y_j] + \sum_{i=1}^{n} \sum_{\substack{j=1\\ j \neq i}}^{n} w_i w_j E[X_i] E[ Y_j] - \mu_{\bar{X}_n} \mu_{\bar{Y}_n}  \label{eq:covSampleMeansNormalized3}
\end{align} %]]></script> <!---_ --></p>

<p>Since <script type="math/tex">E[X_i] = \mu_{X_i} = \mu_{\bar{X}_n}</script> and <script type="math/tex">E[Y_i] = \mu_{Y_i} = \mu_{\bar{Y}_n}</script> (the expected value of the sample mean is the same as the expected value of each element of the sample), we can continue with</p>

<p><script type="math/tex">% <![CDATA[
\begin{align}
  \mbox{cov}(\bar{X}_n,\bar{Y}_n) &= \sum_{i=1}^{n} w_i^2 E[X_i Y_j] + \sum_{i=1}^{n} \sum_{\substack{j=1\\ j \neq i}}^{n} w_i w_j E[X_i] E[ Y_j] - \mu_{\bar{X}_n} \mu_{\bar{Y}_n}  \\
  &= \sum_{i=1}^{n} w_i^2 E[X_i Y_j] + \mu_{\bar{X}_n} \mu_{\bar{Y}_n} \sum_{i=1}^{n} \sum_{\substack{j=1\\ j \neq i}}^{n} w_i w_j - \mu_{\bar{X}_n} \mu_{\bar{Y}_n} \\
 &= \sum_{i=1}^{n} w_i^2 \Big[\mbox{cov}(X_i,Y_i) + \mu_{\bar{X}_i} \mu_{\bar{Y}_i}\Big] + \mu_{\bar{X}_n} \mu_{\bar{Y}_n} \sum_{i=1}^{n} \sum_{\substack{j=1\\ j \neq i}}^{n} w_i w_j - \mu_{\bar{X}_n} \mu_{\bar{Y}_n} \\
 &= \sum_{i=1}^{n} w_i^2 \Big[\mbox{cov}(X_i,Y_i) + \mu_{\bar{X}_n} \mu_{\bar{Y}_n}\Big] + \mu_{\bar{X}_n} \mu_{\bar{Y}_n} \sum_{i=1}^{n} \sum_{\substack{j=1\\ j \neq i}}^{n} w_i w_j - \mu_{\bar{X}_n} \mu_{\bar{Y}_n} \\
 &= \sum_{i=1}^{n} w_i^2 \mbox{cov}(X_i,Y_i) + \sum_{i=1}^{n} w_i^2 \mu_{\bar{X}_n} \mu_{\bar{Y}_n} + \mu_{\bar{X}_n} \mu_{\bar{Y}_n} \sum_{i=1}^{n} \sum_{\substack{j=1\\ j \neq i}}^{n} w_i w_j - \mu_{\bar{X}_n} \mu_{\bar{Y}_n} \\
 &= \sum_{i=1}^{n} w_i^2 \mbox{cov}(X_i,Y_i) + \underbrace{\mu_{\bar{X}_n} \mu_{\bar{Y}_n} \sum_{i=1}^{n} w_i^2 + \mu_{\bar{X}_n} \mu_{\bar{Y}_n} \sum_{i=1}^{n} \sum_{\substack{j=1\\ j \neq i}}^{n} w_i w_j}_{\text{both sums can be merged again}} - \mu_{\bar{X}_n} \mu_{\bar{Y}_n} \\
 &= \sum_{i=1}^{n} w_i^2 \mbox{cov}(X_i,Y_i) + \mu_{\bar{X}_n} \mu_{\bar{Y}_n} \sum_{i=1}^{n} \sum_{j=1}^{n} w_i w_j - \mu_{\bar{X}_n} \mu_{\bar{Y}_n} \\
 &= \sum_{i=1}^{n} w_i^2 \mbox{cov}(X_i,Y_i) + \mu_{\bar{X}_n} \mu_{\bar{Y}_n} \sum_{i=1}^{n} w_i \underbrace{\sum_{j=1}^{n} w_j}_{=1} - \mu_{\bar{X}_n} \mu_{\bar{Y}_n} \\
 &= \sum_{i=1}^{n} w_i^2 \mbox{cov}(X_i,Y_i) + \mu_{\bar{X}_n} \mu_{\bar{Y}_n} \underbrace{\sum_{i=1}^{n} w_i}_{=1}  - \mu_{\bar{X}_n} \mu_{\bar{Y}_n} \\
 &= \sum_{i=1}^{n} w_i^2 \mbox{cov}(X_i,Y_i) + \mu_{\bar{X}_n} \mu_{\bar{Y}_n} - \mu_{\bar{X}_n} \mu_{\bar{Y}_n} \\
 &= \sum_{i=1}^{n} w_i^2 \mbox{cov}(X_i,Y_i)
  \label{eq:covSampleMeansNormalized4}
\end{align} %]]></script> <!---_ --></p>

<p>Finally, since all pairs <script type="math/tex">(X_i, Y_i)</script> are independent and identically distributed (IID), we can write:</p>

<p><script type="math/tex">% <![CDATA[
\begin{align}
  \mbox{cov}(\bar{X}_n,\bar{Y}_n) &= \sum_{i=1}^{n} w_i^2 \mbox{cov}(X_i,Y_i) \\
 &= \mbox{cov}(X,Y) \sum_{i=1}^{n} w_i^2.
  \label{eq:covSampleMeansNormalized5}
\end{align} %]]></script> <!---_ --></p>

<!--- Due to the bilinearity property of the covariance, which states that
$$
\begin{align}
\mbox{cov}(aV+bW, cX + dY) = ac\mbox{cov}(V,X) + ad\mbox{cov}(V,Y) + bc\mbox{cov}(W,X) + bd\mbox{cov}(W,Y),
\end{align}
$$
we can re-write Eq. \eqref{eq:covSampleMeans} in the following way: -->

<p>This simple relation that we finally derived in Eq. \eqref{eq:covSampleMeansNormalized5} will help us later to determine the “memory” of exponentially decaying weighted estimators.</p>

      <footer class="entry-meta">
        <span class="entry-tags"><a href="https://MarkusThill.github.io/tags#Online" title="Pages tagged Online" class="tag"><span class="term">Online</span></a><a href="https://MarkusThill.github.io/tags#Gaussians" title="Pages tagged Gaussians" class="tag"><span class="term">Gaussians</span></a><a href="https://MarkusThill.github.io/tags#Covariances" title="Pages tagged Covariances" class="tag"><span class="term">Covariances</span></a><a href="https://MarkusThill.github.io/tags#Maximum Likelihood Estimation" title="Pages tagged Maximum Likelihood Estimation" class="tag"><span class="term">Maximum Likelihood Estimation</span></a></span>
        
        <span class="author vcard"><span class="fn">Markus Thill</span></span>
        <div class="social-share">
  <ul class="socialcount socialcount-small inline-list">
    <li class="facebook"><a href="https://www.facebook.com/sharer/sharer.php?u=https://MarkusThill.github.io/math/stats/ml/onthe-covariance-of-the-weighted-mean/" title="Share on Facebook"><span class="count"><i class="fa fa-facebook-square"></i> Like</span></a></li>
    <li class="twitter"><a href="https://twitter.com/intent/tweet?text=https://MarkusThill.github.io/math/stats/ml/onthe-covariance-of-the-weighted-mean/" title="Share on Twitter"><span class="count"><i class="fa fa-twitter-square"></i> Tweet</span></a></li>
    <li class="googleplus"><a href="https://plus.google.com/share?url=https://MarkusThill.github.io/math/stats/ml/onthe-covariance-of-the-weighted-mean/" title="Share on Google Plus"><span class="count"><i class="fa fa-google-plus-square"></i> +1</span></a></li>
  </ul>
</div><!-- /.social-share -->

      </footer>
    </div><!-- /.entry-content -->
    <div class="read-more">
  <div class="read-more-header">
    <a href="https://MarkusThill.github.io/markus" class="read-more-btn">About the Author</a>
  </div><!-- /.read-more-header -->
  <div class="read-more-content author-info">
    <h3>Markus Thill</h3>
    <div class="author-container">
      <img class="author-img" src="https://MarkusThill.github.io/images/avatar.jpg" alt="Markus Thill" />
      <div class="author-bio">I studied computer engineering (B.Sc.) and Automation & IT (M.Eng.). Generally, I am interested in machine learning (ML) approaches (in the broadest sense), but particularly in the fields of time series analysis, anomaly detection, Reinforcement Learning (e.g. for board games), Deep Learning (DL) and incremental (on-line) learning procedures. </div>
    </div>
    <div class="author-share">
      <ul class="list-inline social-buttons">
        
          <li><a href="https://github.com/markusthill" target="_blank"><i class="fa fa-github fa-fw"></i></a></li>
        
          <li><a href="https://www.linkedin.com/in/markus-thill-a4991090/" target="_blank"><i class="fa fa-linkedin fa-fw"></i></a></li>
        
      </ul>
      
        <a aria-label="Follow @MarkusThill on GitHub" data-size="large" href="https://github.com/MarkusThill" class="github-button">Follow @MarkusThill</a>
      
      <br>
      
    </div>
  </div>
</div>

    <section id="disqus_thread"></section><!-- /#disqus_thread -->
    <div class="read-more">
  
    <div class="read-more-header">
      <a href="https://MarkusThill.github.io/math/stats/ml/online-estimation-of-weighted-sample-mean-and-coviarance-matrix/" class="read-more-btn">Read More</a>
    </div><!-- /.read-more-header -->
    <div class="read-more-content">
      <h3><a href="https://MarkusThill.github.io/deriving-a-closed-form-solution-of-the-fibonacci-sequence/" title="Deriving a Closed-Form Solution of the Fibonacci Sequence using the Z-Transform">Deriving a Closed-Form Solution of the Fibonacci Sequence using the Z-Transform</a></h3>
      <p>The Fibonacci sequence might be one of the most famous sequences in the field of mathmatics and computer science. Already high school stu...&hellip; <a href="https://MarkusThill.github.io/deriving-a-closed-form-solution-of-the-fibonacci-sequence/">Continue reading</a></p>
    </div><!-- /.read-more-content -->
  
  <div class="read-more-list">
    
      <div class="list-item">
        <h4><a href="https://MarkusThill.github.io/derivation-of-a-weighted-recursive-least-squares-estimator/" title="Derivation of a Weighted Recursive Linear Least Squares Estimator">Derivation of a Weighted Recursive Linear Least Squares Estimator</a></h4>
        <span>Published on May 05, 2019</span>
      </div><!-- /.list-item -->
    
      <div class="list-item">
        <h4><a href="https://MarkusThill.github.io/gaussian-distribution-with-a-diagonal-covariance-matrix/" title="Gaussian Distribution With a Diagonal Covariance Matrix">Gaussian Distribution With a Diagonal Covariance Matrix</a></h4>
        <span>Published on May 04, 2019</span>
      </div><!-- /.list-item -->
    
  </div><!-- /.read-more-list -->
</div><!-- /.read-more -->
  </article>
</div><!-- /#main -->

<script type="text/javascript" src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script type="text/javascript">window.jQuery || document.write('<script type="text/javascript" src="https://MarkusThill.github.io/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script type="text/javascript" src="https://MarkusThill.github.io/assets/js/scripts.min.js"></script>
<script type="text/javascript" async defer id="github-bjs" src="https://buttons.github.io/buttons.js"></script>
<script type="text/javascript">!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^https:/.test(d.location)?'https':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>



<!-- Asynchronous Google Analytics snippet -->
<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-113918188-1', 'auto');
  ga('require', 'linkid', 'linkid.js');
  ga('send', 'pageview');
</script>



    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'markusthill-github-io'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function () {
            var s = document.createElement('script'); s.async = true;
            s.type = 'text/javascript';
            s.src = '//' + disqus_shortname + '.disqus.com/count.js';
            (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
        }());
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>




<script type="text/javascript">
    sharing();
</script>



<div class="footer-wrapper">
  <footer role="contentinfo">
    <span>&copy; 2019 Markus Thill. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="https://github.com/aron-bordin/neo-hpstr-jekyll-theme" rel="nofollow">Neo-HPSTR Theme</a>.</span>

  </footer>
</div><!-- /.footer-wrapper -->

</body>
</html>
