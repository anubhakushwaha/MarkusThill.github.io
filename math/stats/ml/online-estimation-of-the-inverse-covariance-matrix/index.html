<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<!--<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>-->
<!--<script type="text/x-mathjax-config">MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "AMS"} } });</script>-->
<head>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script type="text/x-mathjax-config">MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "AMS"} } });</script>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
<script>
  function resizeIframe(obj) {
    obj.style.height = obj.contentWindow.document.body.scrollHeight + 'px';
  }
</script>

<meta charset="utf-8">
<title>Online Estimation of the Inverse Covariance Matrix &#8211; ML & Stats</title>
<meta name="description" content="Describe your website here.">
<meta name="keywords" content="Online, Gaussians, Covariances, Maximum Likelihood Estimation">



<!-- Open Graph -->
<meta property="og:locale" content="en">
<meta property="og:type" content="article">
<meta property="og:title" content="Online Estimation of the Inverse Covariance Matrix">
<meta property="og:description" content="Describe your website here.">
<meta property="og:url" content="https://MarkusThill.github.io/math/stats/ml/online-estimation-of-the-inverse-covariance-matrix/">
<meta property="og:site_name" content="ML & Stats">
<meta property="og:image" content="https://MarkusThill.github.io/images/stats.jpg">






<link rel="canonical" href="https://MarkusThill.github.io/math/stats/ml/online-estimation-of-the-inverse-covariance-matrix/">
<link href="https://MarkusThill.github.io/feed.xml" type="application/atom+xml" rel="alternate" title="ML & Stats Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no"/>

<!-- For all browsers -->
<link rel="stylesheet" href="https://MarkusThill.github.io/assets/css/main.css">
<link rel="stylesheet" href="https://MarkusThill.github.io/assets/css/jquery.mmenu.all.css">
<link rel="stylesheet" href="https://MarkusThill.github.io/assets/css/jquery.floating-social-share.min.css">
<!-- Webfonts -->
<link href="//fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic" rel="stylesheet" type="text/css">

<meta http-equiv="cleartype" content="on">

<!-- Load Modernizr -->
<script type="text/javascript" src="https://MarkusThill.github.io/assets/js/vendor/modernizr-2.6.2.custom.min.js"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="https://MarkusThill.github.io/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="https://MarkusThill.github.io/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="https://MarkusThill.github.io/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="https://MarkusThill.github.io/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="https://MarkusThill.github.io/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://MarkusThill.github.io/images/apple-touch-icon-144x144-precomposed.png">




<!--<link rel="stylesheet" type="text/css" href="https://cdn.rawgit.com/dreampulse/computer-modern-web-font/master/fonts.css">-->
<link rel="stylesheet" href="/fonts/cmun-serif.css"></link>

<!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Online Estimation of the Inverse Covariance Matrix | ML &amp; Stats</title>
<meta name="generator" content="Jekyll v3.8.6" />
<meta property="og:title" content="Online Estimation of the Inverse Covariance Matrix" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="This post is part 5 of a series of five articles: Online Maximum Likelihood Estimation of (multivariate) Gaussian Distributions Online Estimation of Weighted Sample Mean and Coviarance Matrix The Covariance of weighted Means Memory of the exponentially decaying Estimator for Mean and Covariance Matrix Online Estimation of the Inverse Covariance Matrix \( \def\myX{\mathbf{x}} \def\myM{\mathbf{M}} \def\myY{\mathbf{y}} \def\mySigma{\mathbf{\Sigma}} \def\myM{\mathbf{M}} \def\myT{\mathsf{T}} \) In practice, it is often required to estimate the inverse of the covariance matrix of a Gaussian distribution, for example, when only a Mahalanobis distance between points has to be computed. In an online setting it can be quite expensive to compute the inverse of the covariance matrix again for each new point arriving, since the complexity of the matrix inverse is . As we will see in the following, it is not necessary to estimate the covariance matrix, if only its inverse is needed and furthermore, the inverse can be adapted incrementally in an efficient manner. The results are shown for the general case with a weighted exponentially decaying estimator." />
<meta property="og:description" content="This post is part 5 of a series of five articles: Online Maximum Likelihood Estimation of (multivariate) Gaussian Distributions Online Estimation of Weighted Sample Mean and Coviarance Matrix The Covariance of weighted Means Memory of the exponentially decaying Estimator for Mean and Covariance Matrix Online Estimation of the Inverse Covariance Matrix \( \def\myX{\mathbf{x}} \def\myM{\mathbf{M}} \def\myY{\mathbf{y}} \def\mySigma{\mathbf{\Sigma}} \def\myM{\mathbf{M}} \def\myT{\mathsf{T}} \) In practice, it is often required to estimate the inverse of the covariance matrix of a Gaussian distribution, for example, when only a Mahalanobis distance between points has to be computed. In an online setting it can be quite expensive to compute the inverse of the covariance matrix again for each new point arriving, since the complexity of the matrix inverse is . As we will see in the following, it is not necessary to estimate the covariance matrix, if only its inverse is needed and furthermore, the inverse can be adapted incrementally in an efficient manner. The results are shown for the general case with a weighted exponentially decaying estimator." />
<link rel="canonical" href="https://markusthill.github.io/math/stats/ml/online-estimation-of-the-inverse-covariance-matrix/" />
<meta property="og:url" content="https://markusthill.github.io/math/stats/ml/online-estimation-of-the-inverse-covariance-matrix/" />
<meta property="og:site_name" content="ML &amp; Stats" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-02-03T00:59:52+01:00" />
<script type="application/ld+json">
{"description":"This post is part 5 of a series of five articles: Online Maximum Likelihood Estimation of (multivariate) Gaussian Distributions Online Estimation of Weighted Sample Mean and Coviarance Matrix The Covariance of weighted Means Memory of the exponentially decaying Estimator for Mean and Covariance Matrix Online Estimation of the Inverse Covariance Matrix \\( \\def\\myX{\\mathbf{x}} \\def\\myM{\\mathbf{M}} \\def\\myY{\\mathbf{y}} \\def\\mySigma{\\mathbf{\\Sigma}} \\def\\myM{\\mathbf{M}} \\def\\myT{\\mathsf{T}} \\) In practice, it is often required to estimate the inverse of the covariance matrix of a Gaussian distribution, for example, when only a Mahalanobis distance between points has to be computed. In an online setting it can be quite expensive to compute the inverse of the covariance matrix again for each new point arriving, since the complexity of the matrix inverse is . As we will see in the following, it is not necessary to estimate the covariance matrix, if only its inverse is needed and furthermore, the inverse can be adapted incrementally in an efficient manner. The results are shown for the general case with a weighted exponentially decaying estimator.","headline":"Online Estimation of the Inverse Covariance Matrix","dateModified":"2018-02-03T00:59:52+01:00","datePublished":"2018-02-03T00:59:52+01:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://markusthill.github.io/math/stats/ml/online-estimation-of-the-inverse-covariance-matrix/"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://markusthill.github.io/images/logo.png"}},"url":"https://markusthill.github.io/math/stats/ml/online-estimation-of-the-inverse-covariance-matrix/","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

</head>

<body id="post" class="feature">

<!--[if lt IE 9]><div class="upgrade"><strong><a href="https://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->



<div class="header-menu header-menu-top">
    <ul class="header-item-container">
      <li class="header-item-title header-toggle "><a href="#menu"><h2><i class="fa fa-bars"></i></h2></a></li>
      <li class="header-item-title">
        <a href="https://MarkusThill.github.io/">
          
            <img class="logo" src="https://MarkusThill.github.io/images/logo.png" alt="ML & Stats">
          
          <a href="https://MarkusThill.github.io/" class="title"> ML & Stats</a>
        </a>
      </li>
      
        
        

        
            
                <li class="header-item "><a href="https://MarkusThill.github.io/posts"><h3>Posts</h3></a></li>
            
        
      
        
        

        
          <li class="header-item "><a href="https://MarkusThill.github.io/categories"><h3>Categories</h3></a>
            <ul class="header-submenu">
              
                
                  <li class="sub-item"><a href="https://MarkusThill.github.io/categories/#Electronics">Electronics</a></li>
              
                
                  <li class="sub-item"><a href="https://MarkusThill.github.io/categories/#ML">ML</a></li>
              
                
                  <li class="sub-item"><a href="https://MarkusThill.github.io/categories/#Math">Math</a></li>
              
                
                  <li class="sub-item"><a href="https://MarkusThill.github.io/categories/#Programming">Programming</a></li>
              
                
                  <li class="sub-item"><a href="https://MarkusThill.github.io/categories/#Stats">Stats</a></li>
              
                
                  <li class="sub-item"><a href="https://MarkusThill.github.io/categories/#Template">Template</a></li>
              
                
                  <li class="sub-item"><a href="https://MarkusThill.github.io/categories/#Vector Algebra">Vector Algebra</a></li>
              
            </ul>
          </li>
        
      
        
        

        
            
                <li class="header-item "><a href="https://MarkusThill.github.io/tags"><h3>Tags</h3></a></li>
            
        
      
        
        

        
            
                <li class="header-item "><a href="https://MarkusThill.github.io/markus"><h3>About</h3></a></li>
            
        
      
        
        

        
            
                <li class="header-item "><a href="https://MarkusThill.github.io/"><h3>Home</h3></a></li>
            
        
      
      <li class="header-item"><a href="https://MarkusThill.github.io/search"><h3><i class="fa fa-search"></i></h3></a></li>
    </ul>
  </div>
<div class="entry-header">
  <div class="header-title">
    <div class="header-title-wrap">
      <h1>Online Estimation of the Inverse Covariance Matrix</h1>
      
        <h2><span class="entry-date date published updated"><time datetime="2018-02-03T00:59:52+01:00">February 03, 2018</time></span></h2>
      

      
        <p class="entry-reading-time">
          <i class="fa fa-clock-o"></i>
          
          Reading time ~2 minutes
        </p><!-- /.entry-reading-time -->
      
    </div><!-- /.header-title-wrap -->
  </div><!-- /.header-title -->
</div><!-- /.entry-header -->


<nav id="menu" style="display: none">
  <ul>
    
      
        <li><a href="https://MarkusThill.github.io/"><h3>Home</h3></a></li>
      
    
      
        <li><a href="https://MarkusThill.github.io/markus"><h3>About</h3></a></li>
      
    
      
        <li><a href="https://MarkusThill.github.io/tags"><h3>Tags</h3></a></li>
      
    
      
        <li><a href="https://MarkusThill.github.io/categories"><h3>Categories</h3></a>
          <ul>
            
              
                <li><a href="https://MarkusThill.github.io/categories/#Electronics">Electronics</a></li>
            
              
                <li><a href="https://MarkusThill.github.io/categories/#ML">ML</a></li>
            
              
                <li><a href="https://MarkusThill.github.io/categories/#Math">Math</a></li>
            
              
                <li><a href="https://MarkusThill.github.io/categories/#Programming">Programming</a></li>
            
              
                <li><a href="https://MarkusThill.github.io/categories/#Stats">Stats</a></li>
            
              
                <li><a href="https://MarkusThill.github.io/categories/#Template">Template</a></li>
            
              
                <li><a href="https://MarkusThill.github.io/categories/#Vector Algebra">Vector Algebra</a></li>
            
          </ul>
        </li>
      
    
      
        <li><a href="https://MarkusThill.github.io/posts"><h3>Posts</h3></a></li>
      
    
  </ul>
</nav>




<div id="main" role="main">
  <article class="hentry">
    <div class="entry-content">
        
            <div class="entry-image-index">
              <img src="https://MarkusThill.github.io/images/stats.jpg" alt="Online Estimation of the Inverse Covariance Matrix">
              
            </div>
        
      <h1 class="post-title entry-title">Online Estimation of the Inverse Covariance Matrix</h1>
      <p>This post is part 5 of a series of five articles:</p>
<ol>
  <li><a href="/math/stats/ml/online-estimation-of-gaussians/">Online Maximum Likelihood Estimation of (multivariate) Gaussian Distributions</a></li>
  <li><a href="/math/stats/ml/online-estimation-of-weighted-sample-mean-and-coviarance-matrix/">Online Estimation of Weighted Sample Mean and Coviarance Matrix</a></li>
  <li><a href="/math/stats/ml/onthe-covariance-of-the-weighted-mean/">The Covariance of weighted Means</a></li>
  <li><a href="/math/stats/ml/memory-of-an-exponentially-weighted-estimator-of-the-arithmetic-mean-and-covariance-matrix/">Memory of the exponentially decaying Estimator for Mean and Covariance Matrix</a></li>
  <li><strong><a href="/math/stats/ml/online-estimation-of-the-inverse-covariance-matrix/">Online Estimation of the Inverse Covariance Matrix</a></strong></li>
</ol>

<p>\( <br />
  \def\myX{\mathbf{x}}
  \def\myM{\mathbf{M}}
  \def\myY{\mathbf{y}}
  \def\mySigma{\mathbf{\Sigma}}
  \def\myM{\mathbf{M}}
  \def\myT{\mathsf{T}}
\)</p>

<p>In practice, it is often required to estimate the inverse of the covariance matrix of a Gaussian distribution, for example, when only a Mahalanobis distance between points has to be computed. In an online setting it can be quite expensive to compute the inverse of the covariance matrix again for each new point arriving, since the complexity of the matrix inverse is <script type="math/tex">\mathcal{O(n^3)}</script>. As we will see in the following, it is not necessary to estimate the covariance matrix, if only its inverse is needed and furthermore, the inverse can be adapted incrementally in an efficient manner. The results are shown for the general case with a weighted exponentially decaying estimator.</p>

<!--more-->
<p>Remember that the weighted exponentially decaying estimator could be incrementally adapt the coviarance matrix using the following relations:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
 W_n &= \lambda W_{n-1} + 1 \\
 \mathbf\Delta_n &= \myX_n - \bar\myX_{n-1}  \\
 \bar\myX_{n} &= \bar\myX_{n-1} + \frac{\mathbf\Delta_n}{W_n} \\
 \myM_{n} &= \lambda \myM_{n-1} + \mathbf\Delta_n(\myX_n - \bar\myX_n)^\mathsf{T} \label{eq:M} \\
 \mySigma_n &= \frac{1}{W_n} \myM_{n} \label{eq:Sigma}
\end{align} %]]></script>

<p>Now, in order to compute the inverse, we simply apply the Sherman-Morrison formula <a class="citation" href="#sherman1950adjustment">[1]</a> – a special case of the Woodbury matrix identity <a class="citation" href="#woodbury1950inverting">[2]</a>  – to incrementally update <script type="math/tex">M_n^{-1}</script>. The formula is given by</p>

<p>\begin{align}
  (A+uv^\mathsf{T})^{-1}= A^{-1} - \frac{A^{-1}uv^\myT A^{-1}}{1+v^\myT A^{-1}u}.
\end{align}</p>

<p>If we look at Eq. \eqref{eq:M}, we can identify:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
  A &= \lambda \myM_{n-1} \\
  u &= \mathbf\Delta_n \\
  v &= \myX_n - \bar\myX_n \\
\end{align} %]]></script>

<p>This then leads to:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
  \myM_n^{-1} &= \frac{1}{\lambda}\myM_{n-1}^{-1} - \frac{\frac{1}{\lambda}\myM_{n-1}^{-1}\mathbf\Delta_n(\myX_n - \bar\myX_n)^\myT \myM_{n-1}^{-1}  }{\lambda + (\myX_n - \bar\myX_n)^\myT \myM_{n-1}^{-1} \mathbf\Delta_n}
\end{align} %]]></script>

<p>With Eq. \eqref{eq:Sigma}, we can finally compute the inverse of the covariance matrix with</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
  \mySigma_n^{-1} &= {W_n} \myM_{n}^{-1}.
\end{align} %]]></script>

<h2 id="example-code">Example Code</h2>
<p>In the following some R-code is listed, which illustrates the procedure to incrementally estimate the inverse of the covariance matrix for a set of points collected in the matrix <script type="math/tex">X</script>.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">library</span><span class="p">(</span><span class="n">MASS</span><span class="p">)</span><span class="w">
</span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100000</span><span class="w">
</span><span class="n">d</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="c1"># dimension</span><span class="w">
</span><span class="n">covMat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">matrix</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">-1</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">-1</span><span class="p">,</span><span class="m">3</span><span class="p">,</span><span class="m">-1</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">-1</span><span class="p">,</span><span class="m">3</span><span class="p">),</span><span class="w"> </span><span class="n">nrow</span><span class="o">=</span><span class="m">3</span><span class="p">)</span><span class="w">
</span><span class="n">X</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mvrnorm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">N</span><span class="p">,</span><span class="n">Sigma</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">covMat</span><span class="p">,</span><span class="w">  </span><span class="n">mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">10</span><span class="p">,</span><span class="m">20</span><span class="p">),</span><span class="w"> </span><span class="n">tol</span><span class="o">=</span><span class="w"> </span><span class="m">1e-13</span><span class="p">)</span><span class="w">

</span><span class="n">lambda</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.999</span><span class="w">
</span><span class="n">lambdaSum</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.0</span><span class="w">
</span><span class="n">muhat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">matrix</span><span class="p">(</span><span class="nf">rep</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="n">d</span><span class="p">))</span><span class="w">
</span><span class="n">M</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">.01</span><span class="o">*</span><span class="n">diag</span><span class="p">(</span><span class="n">d</span><span class="p">)</span><span class="w">
</span><span class="n">Mminus</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">.01</span><span class="o">*</span><span class="n">diag</span><span class="p">(</span><span class="n">d</span><span class="p">)</span><span class="w">


</span><span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">nrow</span><span class="p">(</span><span class="n">X</span><span class="p">))</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="n">x</span><span class="o">=</span><span class="n">matrix</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,])</span><span class="w">
  </span><span class="n">lambdaSum</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lambda</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">lambdaSum</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="c1"># Divisor For Covariance Matrix</span><span class="w">
  </span><span class="n">delta</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">muhat</span><span class="w">
  </span><span class="n">muhat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">muhat</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">delta</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">lambdaSum</span><span class="w">
  </span><span class="n">M</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lambda</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">M</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">delta</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">t</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">muhat</span><span class="p">)</span><span class="w">
  </span><span class="n">Sigma</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">M</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">lambdaSum</span><span class="w">

  </span><span class="c1"># Estimation of the inverse</span><span class="w">
  </span><span class="n">Mnum</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1.0</span><span class="o">/</span><span class="n">lambda</span><span class="o">^</span><span class="m">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">Mminus</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">delta</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">t</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">muhat</span><span class="p">)</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">Mminus</span><span class="w">
  </span><span class="n">Mden</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1.0</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1.0</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">lambda</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">t</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">muhat</span><span class="p">)</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">Mminus</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">delta</span><span class="w">
  </span><span class="n">Mminus</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">Mminus</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">lambda</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">Mnum</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">Mden</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="n">print</span><span class="p">(</span><span class="s2">"Error between estimates (should be very small): "</span><span class="p">)</span><span class="w">
</span><span class="n">print</span><span class="p">(</span><span class="n">ginv</span><span class="p">(</span><span class="n">Sigma</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">Mminus</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">lambdaSum</span><span class="p">)</span><span class="w">

</span><span class="n">print</span><span class="p">(</span><span class="s2">"Error between inverse of real and estimated covariance matrix (can be larger because of lambda): "</span><span class="p">)</span><span class="w">
</span><span class="n">print</span><span class="p">(</span><span class="n">ginv</span><span class="p">(</span><span class="n">covMat</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">Mminus</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">lambdaSum</span><span class="p">)</span></code></pre></figure>
<!---* -->

<p>If we run this script, we could get the following output:</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="p">[</span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="s2">"Error between estimates (should be very small): "</span><span class="w">
             </span><span class="p">[,</span><span class="m">1</span><span class="p">]</span><span class="w">         </span><span class="p">[,</span><span class="m">2</span><span class="p">]</span><span class="w">         </span><span class="p">[,</span><span class="m">3</span><span class="p">]</span><span class="w">
</span><span class="p">[</span><span class="m">1</span><span class="p">,]</span><span class="w"> </span><span class="m">6.883383e-15</span><span class="w"> </span><span class="m">4.107825e-15</span><span class="w"> </span><span class="m">1.443290e-15</span><span class="w">
</span><span class="p">[</span><span class="m">2</span><span class="p">,]</span><span class="w"> </span><span class="m">2.664535e-15</span><span class="w"> </span><span class="m">3.108624e-15</span><span class="w"> </span><span class="m">7.494005e-16</span><span class="w">
</span><span class="p">[</span><span class="m">3</span><span class="p">,]</span><span class="w"> </span><span class="m">9.714451e-16</span><span class="w"> </span><span class="m">8.326673e-16</span><span class="w"> </span><span class="m">3.330669e-16</span><span class="w">
</span><span class="p">[</span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="s2">"Error between inverse of real and estimated covariance matrix (can be larger because of lambda): "</span><span class="w">
             </span><span class="p">[,</span><span class="m">1</span><span class="p">]</span><span class="w">         </span><span class="p">[,</span><span class="m">2</span><span class="p">]</span><span class="w">         </span><span class="p">[,</span><span class="m">3</span><span class="p">]</span><span class="w">
</span><span class="p">[</span><span class="m">1</span><span class="p">,]</span><span class="w"> </span><span class="m">-0.044986937</span><span class="w"> </span><span class="m">-0.024795319</span><span class="w"> </span><span class="m">-0.006808579</span><span class="w">
</span><span class="p">[</span><span class="m">2</span><span class="p">,]</span><span class="w"> </span><span class="m">-0.024795319</span><span class="w"> </span><span class="m">-0.031976196</span><span class="w"> </span><span class="m">-0.001583689</span><span class="w">
</span><span class="p">[</span><span class="m">3</span><span class="p">,]</span><span class="w"> </span><span class="m">-0.006808579</span><span class="w"> </span><span class="m">-0.001583689</span><span class="w">  </span><span class="m">0.008351127</span></code></pre></figure>
<!---* -->

<h1 id="references">References</h1>

<ol class="bibliography"><li><span id="sherman1950adjustment">J. Sherman and W. J. Morrison, “Adjustment of an inverse matrix corresponding to a change in one element of a given matrix,” <i>The Annals of Mathematical Statistics</i>, vol. 21, no. 1, pp. 124–127, 1950.</span></li>
<li><span id="woodbury1950inverting">M. A. Woodbury, “Inverting modified matrices,” Princeton University, Princeton, NJ, Memorandum Report 42, Statistical Research Group, 1950.</span></li></ol>

<!--# Further Reading

<ol class="bibliography"><li><span id="DELagyemang2006">M. Agyemang, K. Barker, and R. Alhajj, “A comprehensive survey of numeric and symbolic outlier mining techniques,” <i>Intelligent Data Analysis</i>, vol. 10, no. 6, pp. 521–538, 2006.</span></li>
<li><span id="alarcon2001anomaly">V. Alarcon-Aquino and J. A. Barria, “Anomaly detection in communication networks using wavelets,” <i>IEE Proceedings-Communications</i>, vol. 148, no. 6, pp. 355–362, 2001.</span></li>
<li><span id="alarcon2003anomaly">V. Alarcon Aquino, “Anomaly detection and prediction in communication networks using wavelet transforms,” PhD thesis, Imperial College London, 2003.</span></li>
<li><span id="chandola2009anomaly">V. Chandola, A. Banerjee, and V. Kumar, “Anomaly detection: A survey,” <i>ACM computing surveys (CSUR)</i>, vol. 41, no. 3, p. 15, 2009.</span></li>
<li><span id="GeoHaw09">D. George and J. Hawkins, “Towards a mathematical theory of cortical micro-circuits,” <i>PLoS Comput Biol</i>, vol. 5, no. 10, p. e1000532, 2009.</span></li>
<li><span id="Kanarachos15">S. Kanarachos, J. Mathew, A. Chroneos, and M. Fitzpatrick, “Anomaly detection in time series data using a combination of wavelets, neural networks and Hilbert transform,” in <i>International Conference on Information, Intelligence, Systems and Applications (IISA)</i>, 2015, pp. 1–6.</span></li>
<li><span id="kim2004detecting">S. S. Kim, A. L. N. Reddy, and M. Vannucci, “Detecting traffic anomalies using discrete wavelet transform,” in <i>International Conference on Information Networking</i>, 2004, pp. 951–961.</span></li>
<li><span id="kwon2006wavelet">D. W. Kwon, K. Ko, M. Vannucci, A. L. N. Reddy, and S. Kim, “Wavelet methods for the detection of anomalies and their application to network traffic analysis,” <i>Quality and Reliability Engineering International</i>, vol. 22, no. 8, pp. 953–969, 2006.</span></li>
<li><span id="Laptev15">N. Laptev and S. Amizadeh, “Yahoo anomaly detection dataset S5.” Yahoo Research, 2015.</span></li>
<li><span id="Lavin15">A. Lavin and S. S. Ahmad, “Evaluating Real-time Anomaly Detection Algorithms – the Numenta
	Anomaly Benchmark,” in <i>IEEE Conference on Machine Learning and Applications (ICMLA2015)</i>, 2015.</span></li>
<li><span id="lu2009network">W. Lu and A. A. Ghorbani, “Network anomaly detection based on wavelet analysis,” <i>EURASIP Journal on Advances in Signal Processing</i>, vol. 2009, p. 4, 2009.</span></li>
<li><span id="meyer1995wavelets">Y. Meyer and D. H. Salinger, <i>Wavelets and Operators</i>, vol. 1. Cambridge University Press, 1995.</span></li>
<li><span id="NumentaSwarming">S. Ahmad, “Running Swarms.” May-2017.</span></li>
<li><span id="patcha2007">A. Patcha and J.-M. Park, “An overview of anomaly detection techniques: Existing solutions and latest technological trends,” <i>Comput. Networks</i>, vol. 51, no. 12, pp. 3448–3470, 2007.</span></li>
<li><span id="sherman1950adjustment">J. Sherman and W. J. Morrison, “Adjustment of an inverse matrix corresponding to a change in one element of a given matrix,” <i>The Annals of Mathematical Statistics</i>, vol. 21, no. 1, pp. 124–127, 1950.</span></li>
<li><span id="Thill17b-ITISE">M. Thill, W. Konen, and T. Bäck, “Time Series Anomaly Detection with Discrete Wavelet Transforms and Maximum Likelihood Estimation,” in <i>Intern. Conference on Time Series (ITISE)</i>, 2017.</span></li>
<li><span id="Thill2017SORAD">M. Thill, W. Konen, and T. Bäck, “Online anomaly detection on the Webscope S5 dataset: A comparative study,” in <i>IEEE Conference on Evolving and Adaptive Intelligent Systems (EAIS 2017)</i>, 2017, p. 1.</span></li>
<li><span id="vallis2014">O. Vallis, J. Hochenbaum, and A. Kejariwal, “A Novel Technique for Long-Term Anomaly Detection in the Cloud,” in <i>6th USENIX Workshop on Hot Topics in Cloud Computing, Philadelphia, PA</i>, 2014.</span></li>
<li><span id="woodbury1950inverting">M. A. Woodbury, “Inverting modified matrices,” Princeton University, Princeton, NJ, Memorandum Report 42, Statistical Research Group, 1950.</span></li></ol>-->

      <footer class="entry-meta">
        <span class="entry-tags"><a href="https://MarkusThill.github.io/tags#Online" title="Pages tagged Online" class="tag"><span class="term">Online</span></a><a href="https://MarkusThill.github.io/tags#Gaussians" title="Pages tagged Gaussians" class="tag"><span class="term">Gaussians</span></a><a href="https://MarkusThill.github.io/tags#Covariances" title="Pages tagged Covariances" class="tag"><span class="term">Covariances</span></a><a href="https://MarkusThill.github.io/tags#Maximum Likelihood Estimation" title="Pages tagged Maximum Likelihood Estimation" class="tag"><span class="term">Maximum Likelihood Estimation</span></a></span>
        
        <span class="author vcard"><span class="fn">Markus Thill</span></span>
        <div class="social-share">
  <ul class="socialcount socialcount-small inline-list">
    <li class="facebook"><a href="https://www.facebook.com/sharer/sharer.php?u=https://MarkusThill.github.io/math/stats/ml/online-estimation-of-the-inverse-covariance-matrix/" title="Share on Facebook"><span class="count"><i class="fa fa-facebook-square"></i> Like</span></a></li>
    <li class="twitter"><a href="https://twitter.com/intent/tweet?text=https://MarkusThill.github.io/math/stats/ml/online-estimation-of-the-inverse-covariance-matrix/" title="Share on Twitter"><span class="count"><i class="fa fa-twitter-square"></i> Tweet</span></a></li>
    <li class="googleplus"><a href="https://plus.google.com/share?url=https://MarkusThill.github.io/math/stats/ml/online-estimation-of-the-inverse-covariance-matrix/" title="Share on Google Plus"><span class="count"><i class="fa fa-google-plus-square"></i> +1</span></a></li>
  </ul>
</div><!-- /.social-share -->

      </footer>
    </div><!-- /.entry-content -->
    <div class="read-more">
  <div class="read-more-header">
    <a href="https://MarkusThill.github.io/markus" class="read-more-btn">About the Author</a>
  </div><!-- /.read-more-header -->
  <div class="read-more-content author-info">
    <h3>Markus Thill</h3>
    <div class="author-container">
      <img class="author-img" src="https://MarkusThill.github.io/images/avatar.jpg" alt="Markus Thill" />
      <div class="author-bio">I studied computer engineering (B.Sc.) and Automation & IT (M.Eng.). Generally, I am interested in machine learning (ML) approaches (in the broadest sense), but particularly in the fields of time series analysis, anomaly detection, Reinforcement Learning (e.g. for board games), Deep Learning (DL) and incremental (on-line) learning procedures. </div>
    </div>
    <div class="author-share">
      <ul class="list-inline social-buttons">
        
          <li><a href="https://github.com/markusthill" target="_blank"><i class="fa fa-github fa-fw"></i></a></li>
        
          <li><a href="https://www.linkedin.com/in/markus-thill-a4991090/" target="_blank"><i class="fa fa-linkedin fa-fw"></i></a></li>
        
      </ul>
      
        <a aria-label="Follow @MarkusThill on GitHub" data-size="large" href="https://github.com/MarkusThill" class="github-button">Follow @MarkusThill</a>
      
      <br>
      
    </div>
  </div>
</div>

    <section id="disqus_thread"></section><!-- /#disqus_thread -->
    <div class="read-more">
  
    <div class="read-more-header">
      <a href="https://MarkusThill.github.io/math/stats/ml/memory-of-an-exponentially-weighted-estimator-of-the-arithmetic-mean-and-covariance-matrix/" class="read-more-btn">Read More</a>
    </div><!-- /.read-more-header -->
    <div class="read-more-content">
      <h3><a href="https://MarkusThill.github.io/deriving-a-closed-form-solution-of-the-fibonacci-sequence/" title="Deriving a Closed-Form Solution of the Fibonacci Sequence using the Z-Transform">Deriving a Closed-Form Solution of the Fibonacci Sequence using the Z-Transform</a></h3>
      <p>The Fibonacci sequence might be one of the most famous sequences in the field of mathmatics and computer science. Already high school stu...&hellip; <a href="https://MarkusThill.github.io/deriving-a-closed-form-solution-of-the-fibonacci-sequence/">Continue reading</a></p>
    </div><!-- /.read-more-content -->
  
  <div class="read-more-list">
    
      <div class="list-item">
        <h4><a href="https://MarkusThill.github.io/derivation-of-a-weighted-recursive-least-squares-estimator/" title="Derivation of a Weighted Recursive Linear Least Squares Estimator">Derivation of a Weighted Recursive Linear Least Squares Estimator</a></h4>
        <span>Published on May 05, 2019</span>
      </div><!-- /.list-item -->
    
      <div class="list-item">
        <h4><a href="https://MarkusThill.github.io/gaussian-distribution-with-a-diagonal-covariance-matrix/" title="Gaussian Distribution With a Diagonal Covariance Matrix">Gaussian Distribution With a Diagonal Covariance Matrix</a></h4>
        <span>Published on May 04, 2019</span>
      </div><!-- /.list-item -->
    
  </div><!-- /.read-more-list -->
</div><!-- /.read-more -->
  </article>
</div><!-- /#main -->

<script type="text/javascript" src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script type="text/javascript">window.jQuery || document.write('<script type="text/javascript" src="https://MarkusThill.github.io/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script type="text/javascript" src="https://MarkusThill.github.io/assets/js/scripts.min.js"></script>
<script type="text/javascript" async defer id="github-bjs" src="https://buttons.github.io/buttons.js"></script>
<script type="text/javascript">!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^https:/.test(d.location)?'https':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>



<!-- Asynchronous Google Analytics snippet -->
<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-113918188-1', 'auto');
  ga('require', 'linkid', 'linkid.js');
  ga('send', 'pageview');
</script>



    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'markusthill-github-io'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function () {
            var s = document.createElement('script'); s.async = true;
            s.type = 'text/javascript';
            s.src = '//' + disqus_shortname + '.disqus.com/count.js';
            (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
        }());
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>




<script type="text/javascript">
    sharing();
</script>



<div class="footer-wrapper">
  <footer role="contentinfo">
    <span>&copy; 2019 Markus Thill. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="https://github.com/aron-bordin/neo-hpstr-jekyll-theme" rel="nofollow">Neo-HPSTR Theme</a>.</span>

  </footer>
</div><!-- /.footer-wrapper -->

</body>
</html>
